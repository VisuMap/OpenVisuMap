# CascadingTsne.pyn
#
# This file contains scripts to create multiple maps/embeddings 
# from dataset, then concatenate these maps and embed them in 
# to a single map via tSNE.
# -------------------------------------------------------------
import math, numpy, time, random
import numpy as np

# storage table for intermediate embedding maps.
dsMap = None      # the table to store the intermediate maps.
dsEpochs = 1000   # training epochs for t-SNE algorithm
outMaps = 2       # number of final maps
dsMap3D = False   # the dimension of embedding maps.

TYPE_SEG,  ARC_SEG,  RADIO_SEG,  WEIGHT_SEG = 0, 1, 2, 3
CENTERS_VP,  INTPO_VP,  HIGHLIGHT_VP = 0, 1, 2

#-----------------------------------------------------------

def NewTsneMachine(ds, mtr='Correlation.Cosine Distance',
		epochs=dsEpochs, ppl=0.05, ex0=4.0, ex1=1.0, is3D=dsMap3D):
	tt = New.MdsCluster( ds )
	tt.Show()
	tt.Metric = mtr
	tt.Repeats = 1
	tt.ReadOnly = True
	tt.MaxLoops = epochs
	tt.Is3D = is3D
	tt.InitialExaggeration = ex0
	tt.FinalExaggeration = ex1
	tt.PerplexityRatio = ppl
	tt.AutoScalingTsne = False
	tt.AutoNormalizing = True
	tt.ExaggerationSmoothen = True
	tt.StagedTraining = False
	tt.RefreshFreq = 100
	tt.GlyphScale = 25
	tt.GlyphSize = 0.25
	tt.GlyphOpacity = 0.5
	tt.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")
	return tt

def RunTsne(tt):
	t_start = time.time()
	tt.Reset().Start()
	t_end = time.time()
	if not tt.Completed:
		vv.Return()
	return t_end - t_start

def ShowMapDataset() :
	'''Show the intermediate map data in a heatmap'''
	hm = dsMap.ShowHeatMap()
	hm.Tag = None
	if 'allFeatures' in globals():
		hm.Description = 'Features: ' + '|'.join( allFeatures )
	hm.ScrollingSteps = 3 if dsMap.CS[2].Group == dsMap.CS[1].Group else 2
	hm.SelectionMode = 1	
	hm.NormalizeView()
	hm.AddEventHandler('ItemsSelected', '@ShowColunmsAsMap()')

# Merge all intermediated maps dsMap into a single output map.
def MergeDatasetMaps(desc='OutMap', epochs=dsEpochs, ppl=0.1, repeats=outMaps, is3D=dsMap3D):
	HarmonizeMaps()
	tt = NewTsneMachine(dsMap, epochs=epochs, ppl=ppl, is3D=is3D)
	tt.Metric = 'EuclideanMetric'
	tt.Repeats = repeats
	RunTsne(tt)
	vv.Sleep(250)
	tt.Close()
	vwList = vv.FindFormList('MapSnapshot')
	cnt = len(vwList)
	if cnt >= repeats:
		for k in range(repeats):
			vw = vwList[cnt-repeats+k]
			vw.Title = desc + f'; Repeat: {k+1}'

#---------------------------------------------------------------

def ShowColunmsAsMap():
	mp = pp.Tag
	mpDim = pp.ScrollingSteps
	if pp.SelectedItems.Count == mpDim:
		firstColumn = min(list(dsMap.IndexOfColumns(pp.SelectedItems)))
		if firstColumn % mpDim == 0:
			bList = New.BodyList(pp.GetSelectedNumberTable())
			if (mp == None) or mp.IsDisposed:
				mainList = vv.Dataset.BodyListEnabled()
				for k, b in enumerate(bList):
					b.CopyAttributesFrom( mainList[k] )
				mp = New.MapSnapshot2(bList, vv.Map).Show()
				mp.MapType = 103 if mpDim == 3 else 102
				if mpDim == 2:
					for b in mp.BodyList: b.Z = 0
				pp.Tag = mp
			else:
				if mp.Tag != firstColumn:
					mp.MoveBodiesTo(bList, 30, 50)
			mp.Tag = firstColumn 

def HarmonizeMaps():
	mD = 3 if dsMap3D else 2
	M = mm.ToNumpy(dsMap)
	cc = 2*M.mean(axis=0)
	for k in range(mD, dsMap.Columns):
		c = k-mD
		dd  = np.sum( np.abs(M[:,c] - M[:,k]) )
		ddF = np.sum( np.abs(M[:,c] - cc[k] + M[:,k]) )
		if ddF < dd:
			vv.Echo(f'Flipped {k}-th column')
			M[:,k] = cc[k] - M[:,k]
	mm.CopyToTable(M, dsMap)

def AddMap2Dataset(ds, bsList, is3D, columns, ty, info=''):
	if ds.Rows != bsList.Count:
		vv.Echo(f'Incompatible Map Size: {ds.Rows} != {bsList.Count}')
		return
	ds.CopyValuesFrom(bsList, is3D, columns)
	mpDim = 3 if is3D else 2
	for k in range(mpDim):
		ds.CS[columns+k].Group = ty+1
	vv.Echo(f'{ty}: Map added' + info)

# Merge all open snapshots into a single dataset and display it as a heatmap.
def ConcatSnapshots():
	mList = vv.FindFormList('MapSnapshot')
	if mList.Count == 0:
		vv.Message('No snapshots present')
		vv.Return()
	dimSum = sum([m.MapLayout.Dimension for m in mList])
	ds = New.NumberTable(mList[0].BodyList, dimSum)
	offset = 0
	for k, mp in enumerate(mList):
		mpDim = mp.MapLayout.Dimension
		AddMap2Dataset(ds, mp.BodyList, mpDim==3, offset, k)
		offset += mpDim
		mp.Close()
	ds.ShowHeatMap()
	return ds

def ConcatMapList(mpNames):
	global dsMap
	mpDimList = [vv.Dataset.ReadMap(nm).Dimension for nm in mpNames]
	dimSum, dsMap, offset = sum(mpDimList), None, 0
	for k, nm in enumerate(mpNames):
		mpDim = mpDimList[k]
		bList = vv.Dataset.ReadMapBodyList(nm, True)
		if dsMap == None: 
			dsMap = New.NumberTable(bList, dimSum)
		AddMap2Dataset(dsMap, bList, mpDim==3, offset, k)
		offset += mpDim
	ShowMapDataset()

'''
ConcatMapList([f'A{k}' for k in range(5)])
ConcatMapList(['A0'] + 4*['A4'])
'''

# Sort a list of points via nearst-neighbor.
def SerializeBodies( bList ):
	#The starting point is specified as the first fixed point.
	s = next(filter(lambda b:b.IsFixed, bList))
	bList.remove(s)
	bs = [s]
	while( len(bList) > 0 ):
		minDist = 1e8
		minIdx = -1
		for k, b in enumerate(bList):
			dx = b.X - s.X
			dy = b.Y - s.Y
			dd = dx*dx + dy*dy
			if dd < minDist:
				minDist = dd
				minIdx = k
		bs.append( s )
		s = bList[minIdx]
		bList.remove(s)
	return bs

class CheckTime:
	def __init__(self, msg='Time'):
		self.msg = msg
	def __enter__(self):
		self.start_time = time.time()
	def __exit__(self, type, value, traceback):
		time_diff = time.time()-self.start_time
		vv.Echo(f'{self.msg}: {time_diff:.2f}s')

#-----------------------------------------------

def ArcSegmentation(K):
	cx, cy = numpy.average([(b.X, b.Y) for b in pp.BodyList], axis=0)
	ss = 2.0*math.pi/K
	shift = math.pi + 0.5 * ss
	for b in pp.BodyList:
	  alpha = math.atan2(b.Y-cy, b.X-cx) + shift
	  b.Type = int(alpha/ss) % K
	pp.RedrawBodies()-

def RadioSegmentation(K):
   cx, cy = numpy.average([(b.X, b.Y) for b in pp.BodyList], axis=0)
   minR, maxR = 1e18, 0
   for b in pp.BodyList:
      dx, dy = b.X - cx, b.Y - cy
      R = dx*dx + dy*dy
      minR, maxR = min(minR, R), max(maxR, R)
   minR, maxR = math.sqrt(minR), math.sqrt(maxR)
   ss = (maxR - minR)/K
   for b in pp.BodyList:
      dx, dy = b.X - cx, b.Y - cy
      R = math.sqrt(dx*dx + dy*dy)
      b.Type = min(int(R/ss), K-1)
   pp.RedrawBodies()

def WeightSegmentation(K):
	bs = pp.BodyList
	nt = vv.GetNumberTableView(True)
	colWeight = [math.log(1+math.fabs(it.Value*nt.Rows)) for it in nt.ColumnMean()]
	colIdxes = nt.IndexOfColumns([b.Id for b in bs])	
	minW, maxW = 1e10, 0
	for i, b in enumerate(bs):
		colW = colWeight[colIdxes[i]]
		minW = min(minW, colW)
		maxW = max(maxW, colW)
	ss = (maxW - minW)/K
	for i, b in enumerate(bs):
		colW = colWeight[colIdxes[i]]
		tIdx = int((colW-minW)/ss)
		b.Type = min(tIdx, K-1)
	pp.RedrawBodies()

def Do_ByFeature(flag=TYPE_SEG, K=16):
	global dsMap
	if not hasattr(pp, 'BodyList'):
		vv.Message('This service must be called from a feature-map!')
		vv.Return(0)
	if flag==WEIGHT_SEG:
		WeightSegmentation(K)
	elif flag == ARC_SEG:
		ArcSegmentation(K)
	elif flag == RADIO_SEG:
		RadioSegmentation(K)
	ds = vv.GetNumberTableView(True)		
	tt = NewTsneMachine(ds)
	mpDim = 3 if tt.Is3D else 2
	tList = {b.Type for b in pp.BodyList}
	dsMap = New.NumberTable(ds, len(tList)*mpDim)
	vv.Echo(f'-- Start Feature-Embedding: {len(tList)} feature groups --')
	for k, t in enumerate(tList):
		bList = [b.Id for b in pp.BodyList if b.Type==t]
		dsM = ds.SelectColumnsById( bList )
		if dsM.Columns == 0:
			vv.Message('No feature selected! The parent window must be a feature-map!')
			vv.Return(0)
		pp.Title = f'Feature Group: {t}, Dataset: {dsM.Rows}x{dsM.Columns}'
		pp.SelectedItems = bList
		tt.SetTrainingData(dsM)
		tm = RunTsne(tt)
		tt.Normalize()
		AddMap2Dataset(dsMap, tt.BodyList, (mpDim==3), k*mpDim, t, f'; T:{tm:.1f}')
	tt.Close()
	MergeDatasetMaps(f'Alg: by-feature: {flag}')

#-----------------------------------------------

def VpInterpolation(ds, K):
	cc = []
	for t in [0, 1]:
		centers = ds.SelectRowsById( [r.Id for r in ds.RS if r.Type == t ] )
		cc.append( [it.Value for it in centers.ColumnMean()] )
	return numpy.linspace(cc[0], cc[1], K)

def VpByCenters(ds):
	cc = []
	tList = {r.Type for r in ds.RS if r.Type <= 60}
	for t in tList:
		rList = [r.Id for r in ds.RS if r.Type == t ]
		centers = ds.SelectRowsById(rList)
		cc.append( numpy.array( [it.Value for it in centers.ColumnMean()] ) )
	return cc

def VpHighlighted(ds):
	cc = []
	bList = [b for b in pp.Map.BodyList if b.Highlighted and not b.Disabled]
	bList = SerializeBodies(bList)
	rList = [b.Id for b in bList]
	centers = ds.SelectRowsById(rList)
	return list( mm.ToNumpy(centers) ), rList

def Do_ByViewpoint(flag=CENTERS_VP, K=16):
	global dsMap
	ds = vv.GetNumberTableView(True)
	if flag == CENTERS_VP:
		vpList = VpByCenters(ds)
	elif flag == INTPO_VP:
		vpList = VpInterpolation(ds, K)
	elif flag == HIGHLIGHT_VP:
		vpList, rList = VpHighlighted(ds)
	if len(vpList) == 0:
		vv.Message('No viewpoints have been defined!')
		vv.Return(0)
	vp = New.NumberTable(1, ds.Columns)
	tt = NewTsneMachine(ds)
	mpDim = 3 if tt.Is3D else 2
	dsMap = New.NumberTable(ds, len(vpList)*mpDim)
	vv.Echo(f'-- Start Viewpoints-Embedding: {len(vpList)} viewpoints --')
	for k, CC in enumerate(vpList):
		mm.CopyToTable(CC, vp)
		ds.SubBy(vp)
		tt.SetTrainingData(ds)
		tm = RunTsne(tt)
		tt.Normalize()
		ds.AddTo(vp)
		AddMap2Dataset(dsMap, tt.BodyList, (mpDim==3), k*mpDim, k,
			f'; Training time: {tm:.1f}')
		if flag == HIGHLIGHT_VP:
			dsMap.CS[k*mpDim].Id = rList[k]
	tt.Close()
	MergeDatasetMaps(f'Alg: by-viewpoint: {flag}')

#--------------------------------------------
# Create dataset from maps extracted during the t-SNE training processes.

def CreateMapDataset(is3D=dsMap3D, initSize=0.25, stepSize=0.1, 
		ppl=0.1, ex0=8.0, ex1=1.0, epochs=2*dsEpochs):
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed

	rmInitSize = initSize
	rmStepSize = stepSize
	recordMarker = rmInitSize
	mapCollapsed = True

	# initialize dsMap to store the intermediated maps
	maxStages = 50
	mapDim = 3 if is3D else 2
	dsMap = New.NumberTable(vv.Dataset.BodyListEnabled(), mapDim*maxStages)
	dsMap.Tag = 0

	mds = New.TsneMap()
	mds.PerplexityRatio = ppl 
	mds.InitialExaggeration = ex0
	mds.FinalExaggeration = ex1
	mds.MaxLoops = epochs
	mds.AutoNormalizing = False
	mds.AutoScaling = True
	mds.CentralizingData = True
	mds.StagedTraining = False
	mds.ExaggerationSmoothen = True
	mds.RefreshFreq = 10
	mds.Is3D = is3D
	mds.TracingType = 6
	mds.Repeats = 1
	mds.HistStepSize = 2.0
	mds.ReadOnly = True
	mds.Show()
	mds.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")

	vv.Map.MapType = "Cube" if is3D else "Rectangle"
	vv.Map.Depth = 0.5 * (vv.Map.Height + vv.Map.Width)
	vv.EventManager.OnBodyMoved('@BodyMoved()', mds)
	RunTsne(mds)
	mds.Close()
	dsMap = dsMap.SliceColumn(0, dsMap.Tag)

def BodyMoved():
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed
	
	mapDim = 3 if pp.Is3D else 2
	columns = dsMap.Tag
	span = pp.GlyphSpan

	if (span < recordMarker) and (pp.CurrentLoops != pp.MaxLoops):
		return
	if pp.CurrentLoops < 100:
		return
	if (columns + mapDim) > dsMap.Columns:
		return

	bsList = vv.Dataset.BodyListEnabled()

	# if the map was collapsed we re-check it again.
	if mapCollapsed:
		mapCollapsed = (vv.Math.Pca3DCube(bsList)[0])[mapDim-2] < 1.0
	if mapCollapsed: return

	AddMap2Dataset(dsMap, bsList, pp.Is3D, columns, int(columns/mapDim))

	recordMarker = span + math.ceil(span/3)*rmStepSize   # recordMarker for the next call.
	dsMap.Tag = columns + mapDim
	dsMap.CS[columns].Name = f'Sp:{span}'
	# Mark the cascading stages:
	curExa = float(pp.TheForm.CurrentExaggeration)+0.1
	pp.TheForm.Histogram.AddPoint(curExa, span-0.2)

def Do_Cascading():
	vv.Echo(f'-- Start Cascading Embedding --')
	#CreateMapDataset(initSize=0.2, stepSize=1.0)
	CreateMapDataset(initSize=0.2, stepSize=0.125)
	MergeDatasetMaps('Alg: cascading')

#---------------------------------------------

def Do_Stratify(K=8, gape=0.05, initLevel=0.9, LL=None, dryTry=False):
	global allFeatures
	global dsMap
	ds = vv.GetNumberTableView(True).ApplyFilter(vv.Map.Filter)
	# get std of all columns in to colKey
	colKey = [it.Value for it in ds.SqueezeRows(9, False)]
	maxV = max( colKey )
	mpDim = 3 if dsMap3D else 2
	if LL is None:
		lvList = [initLevel-k*gape for k in range(K)]
		lvList = [v for v in lvList if v>0]
	else:
		lvList = LL

	#lvList.append( list( ds.IndexOfColumns(vv.GroupManager.GetGroupLabels("GC-100")) ) )

	K = len(lvList)
	allFeatures = [cs.Id for cs in ds.ColumnSpecList]
	vv.Echo(f'-- Start Stratified-Embedding: {K} levels --')

	if dryTry:
		dsBw = New.BarView(colKey).Show()
		for k, lv in enumerate(lvList):
			cList = [k for k in range(ds.Columns) if colKey[k]>lv*maxV]
			vv.Echo(f'{k}: Dim/lv: {len(cList)}/{lvList[k]:.2f}')
			for col in cList:
				itm = dsBw.ItemList[col]
				if itm.Group == 0:
					itm.Group = k+1
		dsBw.AutoScaling = True
		dsBw.SortItems(True)		
	else:
		dsMap = New.NumberTable(ds, mpDim*K)
		dsCS = dsMap.ColumnSpecList
		tt = NewTsneMachine(ds,'EuclideanMetric', ex0=6.0, ppl=0.1)
		for k, lv in enumerate(lvList):
			if type(lv) is list:
				cList = lv
				lv = 0
			else:
				cList = [k for k in range(ds.Columns) if colKey[k]>lv*maxV]
			ds2 = ds.SelectColumns(cList)
			tt.SetTrainingData(ds2)
			tm = RunTsne(tt)
			dsCS[k*mpDim].Name = '|'.join(map(str, cList))
			AddMap2Dataset(dsMap, tt.BodyList, tt.Is3D, k*mpDim, k, 
				f';  Dm/Lv/T: {ds2.Columns}/{lv:.3f}/{tm:.1f}s')
		tt.Close()
		MergeDatasetMaps('Alg: Stratify')

#----------------------------------------------------

def Do_StressTest():
	print(f'=== Started at {time.strftime("%H:%M:%S", time.localtime())} ===')

	print('------- Repeating test  --------')
	for k, mp in enumerate(5*['B11']):
		vv.Dataset.OpenMap(mp)
		mds = New.TsneMap().Show()
		mds.MaxLoops = 60
		mds.Repeats = 1
		mds.RefreshFreq = 20
		vv.Echo2(f'{k}: {mp}: ')
		with CheckTime('T'):
			mds.Start()
		mds.Close() if mds.Completed else vv.Return()

	print('------- Dataset size test --------')
	mpList = [f'B{k}' for k in range(1, 14)]
	random.Random(12).shuffle(mpList)
	epochList = [40, 200]
	for n in range(2):
		for k, mp in enumerate(mpList):
			vv.Dataset.OpenMap(mp)
			rows = vv.Dataset.BodyListEnabled().Count
			mds = New.TsneMap().Show()
			mds.MaxLoops = epochList[n]
			mds.RefreshFreq = 20
			mds.Repeats = 1
			vv.Echo2(f'{k}: Training {mp}: {rows} rows;\t')
			with CheckTime('T'):
				mds.Start()
			mds.Close() if mds.Completed else vv.Return()
	
	print('------- Repeating test (2) -------')
	vv.Dataset.OpenMap('B3')
	mds = New.TsneMap()
	mds.Repeats = 4
	mds.MaxLoops = 60
	mds.RefreshFreq = 5
	mds.Show().Start()
	mds.Repeats = 1
	mds.Close()

	print('------- Stratify test -------')
	vv.Dataset.OpenMap('B1')
	for k in range(2):
		Do_Stratify(K=6, gape=0.1, initLevel=0.68)

#----------------------------------------------------

with CheckTime('Total Time'):
	#Do_ByViewpoint(flag=HIGHLIGHT_VP)
	#Do_ByFeature(flag=WEIGHT_SEG, K=4)
	#Do_Cascading()
	#Do_StressTest()
	Do_Stratify()

'''

for k in range(3):
	Do_Stratify(K=6, gape=0.1, initLevel=0.68)

ShowMapDataset()

for k in range(2):
	Do_Stratify(K=8, gape=0.05, initLevel=0.9, dryTry=False)

Do_Stratify(LL=[1.0, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5])

for k in range(3): Do_ByViewpoint(flag=HIGHLIGHT_VP)

Do_ByViewpoint(flag=CENTERS_VP)
Do_ByViewpoint(flag=INTPO_VP, K=16)
Do_ByViewpoint(flag=HIGHLIGHT_VP)
Do_Cascading()

pp = vv.AtlasManager.OpenMap("Vescular", "i4")
Do_ByFeature(flag=TYPE_SEG)
Do_ByFeature(flag=WEIGHT_SEG, K=4)
Do_ByFeature(flag=ARC_SEG, K=12)
Do_ByFeature(flag=RADIO_SEG, K=10)
pp.Close()

MergeDatasetMaps()

dsMap = pp.GetNumberTable()

'''


