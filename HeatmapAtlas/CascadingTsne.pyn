# CascadingTsne.pyn
#
# This file contains scripts to create multiple maps/embeddings 
# from dataset, then concatenate these maps and embed them in 
# to a single map via tSNE.
# -------------------------------------------------------------
import math, numpy, time, random
import numpy as np

# storage table for intermediate embedding maps.
dsMap = None      # the table to store the intermediate maps.
dsEpochs = 4000   # training epochs for t-SNE algorithm
outMaps = 2       # number of final maps
dsMap3D = False   # the dimension of embedding maps.

CENTERS_VP,  INTPO_VP,  HIGHLIGHT_VP = 0, 1, 2

#-----------------------------------------------------------

def NewTsneMachine(ds, mtr='Correlation.Cosine Distance',
		epochs=dsEpochs, ppl=0.05, ex0=4.0, ex1=1.0, is3D=dsMap3D):
	tt = New.MdsCluster( ds )
	tt.Show()
	tt.Metric = mtr
	tt.Repeats = 1
	tt.ReadOnly = True
	tt.MaxLoops = epochs
	tt.Is3D = is3D
	tt.InitialExaggeration = ex0
	tt.FinalExaggeration = ex1
	tt.PerplexityRatio = ppl
	tt.AutoScalingTsne = False
	tt.AutoNormalizing = True
	tt.ExaggerationSmoothen = True
	tt.StagedTraining = False
	tt.RefreshFreq = 50
	tt.GlyphScale = 25
	tt.GlyphSize = 0.25
	tt.GlyphOpacity = 0.5
	tt.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")
	return tt

def RunTsne(tt):
	t_start = time.time()
	tt.Reset().Start()
	t_end = time.time()
	if not tt.Completed:
		vv.Return()
	return t_end - t_start

def ShowMapDataset() :
	'''Show the intermediate map data in a heatmap'''
	hm = dsMap.ShowHeatMap()
	hm.Tag = None
	if 'allFeatures' in globals():
		hm.Description = 'Features: ' + '|'.join( allFeatures )
	hm.ScrollingSteps = 3 if dsMap.CS[2].Group == dsMap.CS[1].Group else 2
	hm.SelectionMode = 1	
	hm.NormalizeView()
	hm.AddEventHandler('ItemsSelected', '@ShowColunmsAsMap()')

# Merge all intermediated maps dsMap into a single output map.
def MergeDatasetMaps(desc='OutMap', epochs=dsEpochs, ppl=0.1, repeats=outMaps, is3D=dsMap3D):
	HarmonizeMaps()
	tt = NewTsneMachine(dsMap, epochs=epochs, ppl=ppl, is3D=is3D)
	tt.Metric = 'EuclideanMetric'
	tt.Repeats = repeats
	RunTsne(tt)
	vv.Sleep(250)
	if repeats == 1: 
		tt.Show2DView()
	tt.Close()
	vwList = vv.FindFormList('MapSnapshot')
	cnt = len(vwList)
	if cnt >= repeats:
		for k in range(repeats):
			vw = vwList[cnt-repeats+k]
			vw.Title = desc + f'; Repeat: {k+1}'
	return vwList[cnt-1]

#---------------------------------------------------------------

def ShowColunmsAsMap():
	mp = pp.Tag
	mpDim = pp.ScrollingSteps
	if pp.SelectedItems.Count == mpDim:
		firstColumn = min(list(dsMap.IndexOfColumns(pp.SelectedItems)))
		if firstColumn % mpDim == 0:
			bList = New.BodyList(pp.GetSelectedNumberTable())
			if (mp == None) or mp.IsDisposed:
				mainList = vv.Dataset.BodyListEnabled()
				for k, b in enumerate(bList):
					b.CopyAttributesFrom( mainList[k] )
				mp = New.MapSnapshot2(bList, vv.Map).Show()
				mp.MapType = 103 if mpDim == 3 else 102
				if mpDim == 2:
					for b in mp.BodyList: b.Z = 0
				pp.Tag = mp
			else:
				if mp.Tag != firstColumn:
					mp.MoveBodiesTo(bList, 30, 50)
			mp.Tag = firstColumn 

def HarmonizeMaps():
	mD = 3 if dsMap3D else 2
	M = mm.ToNumpy(dsMap)
	cc = 2*M.mean(axis=0)
	for k in range(mD, dsMap.Columns):
		c = k-mD
		dd  = np.sum( np.abs(M[:,c] - M[:,k]) )
		ddF = np.sum( np.abs(M[:,c] - cc[k] + M[:,k]) )
		if ddF < dd:
			vv.Echo(f'Flipped {k}-th column')
			M[:,k] = cc[k] - M[:,k]
	mm.CopyToTable(M, dsMap)

def AddMap2Dataset(ds, bsList, is3D, columns, ty, info=''):
	if ds.Rows != bsList.Count:
		vv.Echo(f'Incompatible Map Size: {ds.Rows} != {bsList.Count}')
		return
	ds.CopyValuesFrom(bsList, is3D, columns)
	mpDim = 3 if is3D else 2
	for k in range(mpDim):
		ds.CS[columns+k].Group = ty+1
	vv.Echo(f'{ty}: Map added' + info)
	return columns+mpDim

# Merge all open snapshots into a single dataset and display it as a heatmap.
def ConcatSnapshots():
	global dsMap
	mList = vv.FindFormList('MapSnapshot')
	if mList.Count == 0:
		vv.Message('No snapshots present')
		vv.Return()
	dimSum = sum([m.MapLayout.Dimension for m in mList])
	dsMap = New.NumberTable(mList[0].BodyList, dimSum)
	offset = 0
	for k, mp in enumerate(mList):
		mD = mp.MapLayout.Dimension
		offset = AddMap2Dataset(dsMap, mp.BodyList, mD==3, offset, k)
		mp.Close()
	ShowMapDataset()

def ConcatMapList(mpNames):
	global dsMap
	mpDimList = [vv.Dataset.ReadMap(nm).Dimension for nm in mpNames]
	dimSum, dsMap, offset = sum(mpDimList), None, 0
	for k, nm in enumerate(mpNames):
		mD = mpDimList[k]
		bList = vv.Dataset.ReadMapBodyList(nm, True)
		if dsMap == None: 
			dsMap = New.NumberTable(bList, dimSum)
		offset = AddMap2Dataset(dsMap, bList, mD==3, offset, k)
	ShowMapDataset()

# merge selected maps of an atlas into a dataset.
def MergeAtlasMaps():
	mps = pp.GetSelectedItems()
	ds = None
	for k, item in enumerate(mps):
		mp = item.Open()
		if ds is None:
			ds = New.NumberTable(mp.BodyList, 2*mps.Count)
		for b in mp.BodyList:
			row = ds.IndexOfRow(b.Id)
			if row >= 0:
				R = ds.Matrix[row]
				R[2*k] = b.X
				R[2*k + 1] = b.Y
		for n in [2*k, 2*k+1]:
			ds.CS[n].Group = k+1
			ds.CS[n].Id = 'C'+str(n)
		mp.Close()
	return ds

# Sort a list of points via nearst-neighbor.
def SerializeBodies( bList ):
	#The starting point is specified as the first fixed point.
	fixed = [b for b in bList if b.IsFixed]
	if len(fixed) > 0:
		s = fixed[0]
	else:
		raise Exception("No fixed point found as starting point!")		
	bList.remove(s)
	bs = [s]
	while( len(bList) > 0 ):
		minDist = 1e8
		minIdx = -1
		for k, b in enumerate(bList):
			dx = b.X - s.X
			dy = b.Y - s.Y
			dd = dx*dx + dy*dy
			if dd < minDist:
				minDist = dd
				minIdx = k
		bs.append( s )
		s = bList[minIdx]
		bList.remove(s)
	return bs

class CheckTime:
	def __init__(self, msg='Time'):
		self.msg = msg
	def __enter__(self):
		self.start_time = time.time()
	def __exit__(self, type, value, traceback):
		time_diff = time.time()-self.start_time
		vv.Echo(f'{self.msg}: {time_diff:.2f}s')

#-----------------------------------------------

def VpInterpolation(ds, K):
	selected = vv.Map.SelectedBodies
	types = list({ b.Type for b in selected })
	if len(types) < 2:
		raise Exception("Two clusters must be selected on the map!")
	cc = [None, None]	
	for k in range(2):
		centers = ds.SelectRowsById( [r.Id for r in selected if r.Type == types[k] ] )
		cc[k] = [it.Value for it in centers.ColumnMean()] 
	return numpy.linspace(cc[0], cc[1], K)

def VpByCenters(ds):
	cc = []
	tList = {r.Type for r in ds.RS if r.Type <= 60}
	for t in tList:
		rList = [r.Id for r in ds.RS if r.Type == t ]
		centers = ds.SelectRowsById(rList)
		cc.append( numpy.array( [it.Value for it in centers.ColumnMean()] ) )
	return cc

# The current map must marker a set of points highlighted as viewpoints; and marker one
# point of them fixed as the starting point.
#
def VpHighlighted(ds):
	cc = []
	bList = [b for b in pp.Map.BodyList if b.Highlighted and not b.Disabled]
	bList = SerializeBodies(bList)
	rList = [b.Id for b in bList]
	centers = ds.SelectRowsById(rList)
	return list( mm.ToNumpy(centers) ), rList

def Do_ByViewpoint(flag=CENTERS_VP, K=16):
	global dsMap
	ds = vv.GetNumberTableView(True).ApplyFilter(vv.Map.Filter)
	if flag == CENTERS_VP:
		vpList = VpByCenters(ds)
	elif flag == INTPO_VP:
		vpList = VpInterpolation(ds, K)
	elif flag == HIGHLIGHT_VP:
		vpList, rList = VpHighlighted(ds)
	if len(vpList) == 0:
		vv.Message('No viewpoints have been defined!')
		vv.Return(0)
	vp = New.NumberTable(1, ds.Columns)
	tt = NewTsneMachine(ds)
	mpDim = 3 if tt.Is3D else 2
	dsMap = New.NumberTable(ds, len(vpList)*mpDim)
	vv.Echo(f'-- Start Viewpoints-Embedding: {len(vpList)} viewpoints --')
	for k, CC in enumerate(vpList):
		mm.CopyToTable(CC, vp)
		ds.SubBy(vp)
		tt.SetTrainingData(ds)
		tm = RunTsne(tt)
		tt.Normalize()
		ds.AddTo(vp)
		AddMap2Dataset(dsMap, tt.BodyList, (mpDim==3), k*mpDim, k,
			f'; Training time: {tm:.1f}')
		if flag == HIGHLIGHT_VP:
			dsMap.CS[k*mpDim].Id = rList[k]
	tt.Close()
	return MergeDatasetMaps(f'Alg: by-viewpoint: {flag}')

#--------------------------------------------
# Create dataset from maps extracted during the t-SNE training processes.

def CreateMapDataset(is3D=dsMap3D, initSize=0.25, stepSize=0.1, 
		ppl=0.1, ex0=8.0, ex1=1.0, epochs=2*dsEpochs):
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed

	rmInitSize = initSize
	rmStepSize = stepSize
	recordMarker = rmInitSize
	mapCollapsed = True

	# initialize dsMap to store the intermediated maps
	maxStages = 50
	mapDim = 3 if is3D else 2
	dsMap = New.NumberTable(vv.Dataset.BodyListEnabled(), mapDim*maxStages)
	dsMap.Tag = 0

	mds = New.TsneMap()
	mds.PerplexityRatio = ppl 
	mds.InitialExaggeration = ex0
	mds.FinalExaggeration = ex1
	mds.MaxLoops = epochs
	mds.AutoNormalizing = False
	mds.AutoScaling = True
	mds.CentralizingData = True
	mds.StagedTraining = False
	mds.ExaggerationSmoothen = True
	mds.RefreshFreq = 10
	mds.Is3D = is3D
	mds.TracingType = 6
	mds.Repeats = 1
	mds.HistStepSize = 2.0
	mds.ReadOnly = True
	mds.Show()
	mds.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")

	vv.Map.MapType = "Cube" if is3D else "Rectangle"
	vv.Map.Depth = 0.5 * (vv.Map.Height + vv.Map.Width)
	vv.EventManager.OnBodyMoved('@BodyMoved()', mds)
	RunTsne(mds)
	mds.Close()
	dsMap = dsMap.SliceColumn(0, dsMap.Tag)

def BodyMoved():
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed
	
	mapDim = 3 if pp.Is3D else 2
	columns = dsMap.Tag
	span = pp.GlyphSpan

	if (span < recordMarker) and (pp.CurrentLoops != pp.MaxLoops):
		return
	if pp.CurrentLoops < 100:
		return
	if (columns + mapDim) > dsMap.Columns:
		return

	bsList = vv.Dataset.BodyListEnabled()

	# if the map was collapsed we re-check it again.
	if mapCollapsed:
		mapCollapsed = (vv.Math.Pca3DCube(bsList)[0])[mapDim-2] < 1.0
	if mapCollapsed: return

	AddMap2Dataset(dsMap, bsList, pp.Is3D, columns, int(columns/mapDim))

	recordMarker = span + math.ceil(span/3)*rmStepSize   # recordMarker for the next call.
	dsMap.Tag = columns + mapDim
	dsMap.CS[columns].Name = f'Sp:{span}'
	# Mark the cascading stages:
	curExa = float(pp.TheForm.CurrentExaggeration)+0.1
	pp.TheForm.Histogram.AddPoint(curExa, span-0.2)

def Do_Cascading():
	vv.Echo(f'-- Start Cascading Embedding --')
	#CreateMapDataset(initSize=0.2, stepSize=1.0)
	CreateMapDataset(initSize=0.2, stepSize=0.125)
	return MergeDatasetMaps('Alg: cascading')

#---------------------------------------------
def NewFeatureChain(K=8, initLevel=0.9, gape=0.05, showChain=False):
	LL = [initLevel-k*gape for k in range(K)]
	LL = [v for v in LL if v>0]
	return NewFeatureChain0(LL, showChain=showChain)

def GetVarianceKey():
	ds = vv.GetNumberTableView(True)
	return ds.SqueezeRows(9, False)

def NewFeatureChain0(LL, showChain=False, fKey=None):
	global allFeatures
	global dsMap

	if fKey is None: fKey = GetVarianceKey()
	for item in fKey: 
		item.Group = 0
	colKey = [it.Value for it in fKey]
	maxV = max( colKey )
	mpDim = 3 if dsMap3D else 2

	K = len(LL)
	allFeatures = [it.Id for it in fKey]
	vv.Echo(f'-- Start Stratified-Embedding: {K} levels --')

	if showChain:
		dsBw = New.BarView(fKey).Show()
		LL = [ round(x, 3) for x in LL]
		dimList = []
		for k, lv in enumerate(LL):
			cList = [k for k in range(fKey.Count) if colKey[k]>lv*maxV]
			dimList.append(len(cList))
			for col in cList:
				itm = dsBw.ItemList[col]
				if itm.Group == 0:
					itm.Group = k+1
		print(f'LL = {LL}\nDims = {dimList}')
		dsBw.AutoScaling = True
		dsBw.SortItems(False)		

	fChain = []
	for lv in LL:
		fChain.append( [fKey[k].Id for k in range(fKey.Count) if colKey[k]>lv*maxV] )
	return fChain

def ShowSortedFeatures():
	ds = vv.GetNumberTableView(False)
	colKey = [it.Value for it in ds.SqueezeRows(9, False)]
	dsBw = New.BarView(colKey).Show()
	for k in range(ds.Columns):
		dsBw.ItemList[k].Id = ds.ColumnSpecList[k].Id
	dsBw.SortItems(False)
	return dsBw

def GetFeatureChain(K):
	dsBw = ShowSortedFeatures()
	fList = [item.Id for item in dsBw.ItemList]
	dsBw.Close()
	fChain = []
	n = 2
	for k in range(K):
		fChain.append(fList[0:n])
		n += n
	return fChain

def NewFeatureChain2(dsList):
	fChain = None
	K = 8
	for nm in dsList:
		vv.Folder.OpenDataset(nm)
		fc = GetFeatureChain(K)
		fc = list( map(set, fc) )
		if fChain == None:
			fChain = fc
		else:
			fChain = [ fChain[k] | fc[k] for k in range(K) ]
	fChain = [list(f) for f in fChain]
	return fChain

# split the whole feature space by the column type, excluding the type 0.
def NewFeatureChain3():
	if not hasattr(pp, 'BodyList'):
		vv.Message('This service must be called from a feature-map!')
		vv.Return(0)
	tList = {b.Type for b in pp.BodyList if b.Type>0}
	fChain = []
	for k, t in enumerate(tList):
		fChain.append( [b.Id for b in pp.BodyList if b.Type==t] )
	for k, f in enumerate(fChain):
		print(f'{k}: {len(f)}')
	return fChain

def SaveFeatureChain(fChain, keyName):
	vv.GroupManager.SetGroupLabels(keyName, ['&'.join(x) for x in fChain])

def LoadFeatureChain(keyName):
	fChain = vv.GroupManager.GetGroupLabels(keyName)
	if fChain == None:
		print(f'Cannot find group "{keyName}"!')
		return None
	return [f.split('&') for f in fChain]

def NewFeatureChain4(fKey, LL):
	bv = New.BarView(fKey)
	bv.SortItems(False)
	fKey = [it.Id for it in bv.ItemList]
	bv.Close()
	fChain = []
	for n in LL:
		fChain.append( fKey[0:n] )
	return fChain


def Do_Stratify(fChain, ex0=4.0, ppl=0.05):
	global dsMap
	ds = vv.GetNumberTableView(True)
	mD = 3 if dsMap3D else 2
	dsMap = New.NumberTable(ds, mD*len(fChain))
	fLen = [len(f) for f in fChain]
	print(f'Creating {len(fChain)} feature maps: {fLen}...')
	print(f' ______________\tFeatures\tTime _____________')
	tt = NewTsneMachine(ds,'EuclideanMetric', ex0=ex0, ppl=ppl)
	#tt = NewTsneMachine(ds,'Correlation.Cosine Distance', ex0=ex0, ppl=ppl)
	for k, fs in enumerate(fChain):
		ds2 = ds.SelectColumnsById(fs)
		ds2.Centralize()
		tt.SetTrainingData(ds2)
		tm = RunTsne(tt)
		dsMap.ColumnSpecList[k*mD].Name = '|'.join(fs)
		AddMap2Dataset(dsMap,tt.BodyList,tt.Is3D,k*mD,k,f',\t{ds2.Columns}\t{tm:.1f}s')
	tt.Close()
	return MergeDatasetMaps('Alg: Stratify')

#----------------------------------------------------

if vv.EventSource.Item == 'Merge Maps':
	dsMap = MergeAtlasMaps()
	MergeDatasetMaps('Merge')
	vv.Return()

with CheckTime('Total Time'):
	#Do_ByViewpoint(flag=CENTERS_VP)
	#Do_ByViewpoint(flag=HIGHLIGHT_VP)
	#Do_ByViewpoint(flag=INTPO_VP, K=32)
	#Do_Cascading()
	if 'fChain' not in globals(): raise Exception('No feature-chain speficied')
	Do_Stratify(fChain, 4.0, 0.05)
	#ShowMapDataset()


'''

with CheckTime('Total Time'):
	Do_StressTest()


for mp in ['A3', 'A4', 'A5', 'A6', 'A7']:
	print(f'\nTraining map {mp}...')
	vv.Dataset.OpenMap(mp)
	Do_Stratify(fChain, 4.0, 0.05)

LL = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4]

fChain = NewFeatureChain(8, 0.9, 0.05,  showChain=True)
fChain = NewFeatureChain0([0.9, 0.8, 0.7, 0.6, 0.5, 0.4], True, None)
fChain = LoadFeatureChain('FeatureChain')

fChain = NewFeatureChain0([0.85, 0.825, 0.8, 0.775, 0.75, 0.725, 0.7], True, keyItems)
fChain = NewFeatureChain(12, 0.96, 0.005, True)

keyItems = pp.ItemList

fChain = 8*[[c.Id for c in vv.Dataset.ColumnSpecList]]

fChain = NewFeatureChain4(GetVarianceKey(), 16*[20913])

Do_Stratify(fChain, 4.0, 0.05)

fChain = NewFeatureChain(8, 0.98, 0.0075,  showChain=True)
Do_Stratify(fChain, 4.0, 0.05)
Do_Stratify(fChain, 4.0, 0.05)


SaveFeatureChain(fChain, 'FeatureChain2')
fChain = LoadFeatureChain('FeatureChain2')

dsList = ['Perivascular',  'TCellBreast', 'BreastCancer', 'Myeloid', 'Vascular-C']
fChain = NewFeatureChain2(dsList)
SaveFeatureChain(fChain, 'FeatureChain')
fLen = [len(f) for f in fChain]
print(f'Creating {len(fChain)} feature maps: {fLen}...')

fChain = NewFeatureChain2(['Perivascular', 'Vascular-C'])
print(f'{fChain[0]}...')

fChain = NewFeatureChain3()

fChain = LoadFeatureChain('FeatureChain')

ConcatMapList(['A0', 'A1', 'A2', 'A2', 'A2'])
ConcatSnapshots()

[it.Id for it in keyItems][0:5]

ShowSortedFeatures()

ShowMapDataset()
MergeDatasetMaps()
dsMap = pp.GetNumberTable()

vv.StartProcess(`https://www.ncbi.nlm.nih.gov/gene/?term=${pp.SelectedItems[0]}`) // for JS.
vv.StartProcess(f'https://www.ncbi.nlm.nih.gov/gene/?term={pp.SelectedItems[0]}')

for k, nm in enumerate(vv.Folder.DatasetNameList):
	vv.Echo(f'{k} : {nm}')

dsList = [0, 2, 3, 4, 7, 12, 13]

'''


