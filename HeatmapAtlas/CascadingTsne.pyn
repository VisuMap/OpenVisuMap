# CascadingTsne.pyn
#
# This file contains scripts to create multiple maps/embeddings 
# from dataset, then concatenate these maps and embed them in 
# to a single map via tSNE.
# -------------------------------------------------------------
import math, numpy, time, random
import numpy as np

# storage table for intermediate embedding maps.
dsMap = None      # the table to store the intermediate maps.
dsEpochs = 2000   # training epochs for t-SNE algorithm
outMaps = 1       # number of final maps
dsMap3D = False   # the dimension of embedding maps.

CENTERS_VP,  INTPO_VP,  HIGHLIGHT_VP = 0, 1, 2

#-----------------------------------------------------------

def NewTsneMachine(ds, mtr='Correlation.Cosine Distance',
		epochs=dsEpochs, ppl=0.05, ex0=4.0, ex1=1.0, is3D=dsMap3D):
	tt = New.MdsCluster( ds )
	tt.Show()
	tt.Metric = mtr
	tt.Repeats = 1
	tt.ReadOnly = True
	tt.MaxLoops = epochs
	tt.Is3D = is3D
	tt.InitialExaggeration = ex0
	tt.FinalExaggeration = ex1
	tt.PerplexityRatio = ppl
	tt.AutoScalingTsne = False
	tt.AutoNormalizing = True
	tt.ExaggerationSmoothen = True
	tt.StagedTraining = False
	tt.RefreshFreq = 100
	tt.GlyphScale = 25
	tt.GlyphSize = 0.25
	tt.GlyphOpacity = 0.5
	tt.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")
	return tt

def RunTsne(tt):
	t_start = time.time()
	tt.Reset().Start()
	t_end = time.time()
	if not tt.Completed:
		vv.Return()
	return t_end - t_start

def ShowMapDataset() :
	'''Show the intermediate map data in a heatmap'''
	hm = dsMap.ShowHeatMap()
	hm.Tag = None
	if 'allFeatures' in globals():
		hm.Description = 'Features: ' + '|'.join( allFeatures )
	hm.ScrollingSteps = 3 if dsMap.CS[2].Group == dsMap.CS[1].Group else 2
	hm.SelectionMode = 1	
	hm.NormalizeView()
	hm.AddEventHandler('ItemsSelected', '@ShowColunmsAsMap()')

# Merge all intermediated maps dsMap into a single output map.
def MergeDatasetMaps(desc='OutMap', epochs=dsEpochs, ppl=0.1, repeats=outMaps, is3D=dsMap3D):
	HarmonizeMaps()
	tt = NewTsneMachine(dsMap, epochs=epochs, ppl=ppl, is3D=is3D)
	tt.Metric = 'EuclideanMetric'
	tt.Repeats = repeats
	RunTsne(tt)
	vv.Sleep(250)
	if repeats == 1: 
		tt.Show2DView()
	tt.Close()
	vwList = vv.FindFormList('MapSnapshot')
	cnt = len(vwList)
	if cnt >= repeats:
		for k in range(repeats):
			vw = vwList[cnt-repeats+k]
			vw.Title = desc + f'; Repeat: {k+1}'

#---------------------------------------------------------------

def ShowColunmsAsMap():
	mp = pp.Tag
	mpDim = pp.ScrollingSteps
	if pp.SelectedItems.Count == mpDim:
		firstColumn = min(list(dsMap.IndexOfColumns(pp.SelectedItems)))
		if firstColumn % mpDim == 0:
			bList = New.BodyList(pp.GetSelectedNumberTable())
			if (mp == None) or mp.IsDisposed:
				mainList = vv.Dataset.BodyListEnabled()
				for k, b in enumerate(bList):
					b.CopyAttributesFrom( mainList[k] )
				mp = New.MapSnapshot2(bList, vv.Map).Show()
				mp.MapType = 103 if mpDim == 3 else 102
				if mpDim == 2:
					for b in mp.BodyList: b.Z = 0
				pp.Tag = mp
			else:
				if mp.Tag != firstColumn:
					mp.MoveBodiesTo(bList, 30, 50)
			mp.Tag = firstColumn 

def HarmonizeMaps():
	mD = 3 if dsMap3D else 2
	M = mm.ToNumpy(dsMap)
	cc = 2*M.mean(axis=0)
	for k in range(mD, dsMap.Columns):
		c = k-mD
		dd  = np.sum( np.abs(M[:,c] - M[:,k]) )
		ddF = np.sum( np.abs(M[:,c] - cc[k] + M[:,k]) )
		if ddF < dd:
			vv.Echo(f'Flipped {k}-th column')
			M[:,k] = cc[k] - M[:,k]
	mm.CopyToTable(M, dsMap)

def AddMap2Dataset(ds, bsList, is3D, columns, ty, info=''):
	if ds.Rows != bsList.Count:
		vv.Echo(f'Incompatible Map Size: {ds.Rows} != {bsList.Count}')
		return
	ds.CopyValuesFrom(bsList, is3D, columns)
	mpDim = 3 if is3D else 2
	for k in range(mpDim):
		ds.CS[columns+k].Group = ty+1
	vv.Echo(f'{ty}: Map added' + info)
	return columns+mpDim

# Merge all open snapshots into a single dataset and display it as a heatmap.
def ConcatSnapshots():
	global dsMap
	mList = vv.FindFormList('MapSnapshot')
	if mList.Count == 0:
		vv.Message('No snapshots present')
		vv.Return()
	dimSum = sum([m.MapLayout.Dimension for m in mList])
	dsMap = New.NumberTable(mList[0].BodyList, dimSum)
	offset = 0
	for k, mp in enumerate(mList):
		mD = mp.MapLayout.Dimension
		offset = AddMap2Dataset(dsMap, mp.BodyList, mD==3, offset, k)
		mp.Close()
	ShowMapDataset()

def ConcatMapList(mpNames):
	global dsMap
	mpDimList = [vv.Dataset.ReadMap(nm).Dimension for nm in mpNames]
	dimSum, dsMap, offset = sum(mpDimList), None, 0
	for k, nm in enumerate(mpNames):
		mD = mpDimList[k]
		bList = vv.Dataset.ReadMapBodyList(nm, True)
		if dsMap == None: 
			dsMap = New.NumberTable(bList, dimSum)
		offset = AddMap2Dataset(dsMap, bList, mD==3, offset, k)
	ShowMapDataset()


# Sort a list of points via nearst-neighbor.
def SerializeBodies( bList ):
	#The starting point is specified as the first fixed point.
	fixed = [b for b in bList if b.IsFixed]
	if len(fixed) > 0:
		s = fixed[0]
	else:
		raise Exception("No fixed point found as starting point!")		
	bList.remove(s)
	bs = [s]
	while( len(bList) > 0 ):
		minDist = 1e8
		minIdx = -1
		for k, b in enumerate(bList):
			dx = b.X - s.X
			dy = b.Y - s.Y
			dd = dx*dx + dy*dy
			if dd < minDist:
				minDist = dd
				minIdx = k
		bs.append( s )
		s = bList[minIdx]
		bList.remove(s)
	return bs

class CheckTime:
	def __init__(self, msg='Time'):
		self.msg = msg
	def __enter__(self):
		self.start_time = time.time()
	def __exit__(self, type, value, traceback):
		time_diff = time.time()-self.start_time
		vv.Echo(f'{self.msg}: {time_diff:.2f}s')

#-----------------------------------------------

def VpInterpolation(ds, K):
	selected = vv.Map.SelectedBodies
	types = list({ b.Type for b in selected })
	if len(types) < 2:
		raise Exception("Two clusters must be selected on the map!")
	cc = [None, None]	
	for k in range(2):
		centers = ds.SelectRowsById( [r.Id for r in selected if r.Type == types[k] ] )
		cc[k] = [it.Value for it in centers.ColumnMean()] 
	return numpy.linspace(cc[0], cc[1], K)

def VpByCenters(ds):
	cc = []
	tList = {r.Type for r in ds.RS if r.Type <= 60}
	for t in tList:
		rList = [r.Id for r in ds.RS if r.Type == t ]
		centers = ds.SelectRowsById(rList)
		cc.append( numpy.array( [it.Value for it in centers.ColumnMean()] ) )
	return cc

# The current map must marker a set of points highlighted as viewpoints; and marker one
# point of them fixed as the starting point.
#
def VpHighlighted(ds):
	cc = []
	bList = [b for b in pp.Map.BodyList if b.Highlighted and not b.Disabled]
	bList = SerializeBodies(bList)
	rList = [b.Id for b in bList]
	centers = ds.SelectRowsById(rList)
	return list( mm.ToNumpy(centers) ), rList

def Do_ByViewpoint(flag=CENTERS_VP, K=16):
	global dsMap
	ds = vv.GetNumberTableView(True).ApplyFilter(vv.Map.Filter)
	if flag == CENTERS_VP:
		vpList = VpByCenters(ds)
	elif flag == INTPO_VP:
		vpList = VpInterpolation(ds, K)
	elif flag == HIGHLIGHT_VP:
		vpList, rList = VpHighlighted(ds)
	if len(vpList) == 0:
		vv.Message('No viewpoints have been defined!')
		vv.Return(0)
	vp = New.NumberTable(1, ds.Columns)
	tt = NewTsneMachine(ds)
	mpDim = 3 if tt.Is3D else 2
	dsMap = New.NumberTable(ds, len(vpList)*mpDim)
	vv.Echo(f'-- Start Viewpoints-Embedding: {len(vpList)} viewpoints --')
	for k, CC in enumerate(vpList):
		mm.CopyToTable(CC, vp)
		ds.SubBy(vp)
		tt.SetTrainingData(ds)
		tm = RunTsne(tt)
		tt.Normalize()
		ds.AddTo(vp)
		AddMap2Dataset(dsMap, tt.BodyList, (mpDim==3), k*mpDim, k,
			f'; Training time: {tm:.1f}')
		if flag == HIGHLIGHT_VP:
			dsMap.CS[k*mpDim].Id = rList[k]
	tt.Close()
	MergeDatasetMaps(f'Alg: by-viewpoint: {flag}')

#--------------------------------------------
# Create dataset from maps extracted during the t-SNE training processes.

def CreateMapDataset(is3D=dsMap3D, initSize=0.25, stepSize=0.1, 
		ppl=0.1, ex0=8.0, ex1=1.0, epochs=2*dsEpochs):
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed

	rmInitSize = initSize
	rmStepSize = stepSize
	recordMarker = rmInitSize
	mapCollapsed = True

	# initialize dsMap to store the intermediated maps
	maxStages = 50
	mapDim = 3 if is3D else 2
	dsMap = New.NumberTable(vv.Dataset.BodyListEnabled(), mapDim*maxStages)
	dsMap.Tag = 0

	mds = New.TsneMap()
	mds.PerplexityRatio = ppl 
	mds.InitialExaggeration = ex0
	mds.FinalExaggeration = ex1
	mds.MaxLoops = epochs
	mds.AutoNormalizing = False
	mds.AutoScaling = True
	mds.CentralizingData = True
	mds.StagedTraining = False
	mds.ExaggerationSmoothen = True
	mds.RefreshFreq = 10
	mds.Is3D = is3D
	mds.TracingType = 6
	mds.Repeats = 1
	mds.HistStepSize = 2.0
	mds.ReadOnly = True
	mds.Show()
	mds.AddContextMenu("Show Map Dataset", "@ShowMapDataset()")

	vv.Map.MapType = "Cube" if is3D else "Rectangle"
	vv.Map.Depth = 0.5 * (vv.Map.Height + vv.Map.Width)
	vv.EventManager.OnBodyMoved('@BodyMoved()', mds)
	RunTsne(mds)
	mds.Close()
	dsMap = dsMap.SliceColumn(0, dsMap.Tag)

def BodyMoved():
	global recordMarker
	global rmStepSize
	global rmInitSize
	global dsMap
	global mapCollapsed
	
	mapDim = 3 if pp.Is3D else 2
	columns = dsMap.Tag
	span = pp.GlyphSpan

	if (span < recordMarker) and (pp.CurrentLoops != pp.MaxLoops):
		return
	if pp.CurrentLoops < 100:
		return
	if (columns + mapDim) > dsMap.Columns:
		return

	bsList = vv.Dataset.BodyListEnabled()

	# if the map was collapsed we re-check it again.
	if mapCollapsed:
		mapCollapsed = (vv.Math.Pca3DCube(bsList)[0])[mapDim-2] < 1.0
	if mapCollapsed: return

	AddMap2Dataset(dsMap, bsList, pp.Is3D, columns, int(columns/mapDim))

	recordMarker = span + math.ceil(span/3)*rmStepSize   # recordMarker for the next call.
	dsMap.Tag = columns + mapDim
	dsMap.CS[columns].Name = f'Sp:{span}'
	# Mark the cascading stages:
	curExa = float(pp.TheForm.CurrentExaggeration)+0.1
	pp.TheForm.Histogram.AddPoint(curExa, span-0.2)

def Do_Cascading():
	vv.Echo(f'-- Start Cascading Embedding --')
	#CreateMapDataset(initSize=0.2, stepSize=1.0)
	CreateMapDataset(initSize=0.2, stepSize=0.125)
	MergeDatasetMaps('Alg: cascading')

#---------------------------------------------

def NewFeatureChain(K=8, initLevel=0.9, gape=0.05, LL=None, showChain=False):
	global allFeatures
	global dsMap
	ds = vv.GetNumberTableView(True)
	colKey = [it.Value for it in ds.SqueezeRows(9, False)]
	maxV = max( colKey )
	mpDim = 3 if dsMap3D else 2
	if LL is None:
		lvList = [initLevel-k*gape for k in range(K)]
		lvList = [v for v in lvList if v>0]
	else:
		lvList = LL

	K = len(lvList)
	allFeatures = [cs.Id for cs in ds.ColumnSpecList]
	vv.Echo(f'-- Start Stratified-Embedding: {K} levels --')

	if showChain:
		dsBw = New.BarView(colKey).Show()
		lvList = [ round(x, 3) for x in lvList]
		dimList = []
		for k, lv in enumerate(lvList):
			cList = [k for k in range(ds.Columns) if colKey[k]>lv*maxV]
			dimList.append(len(cList))
			for col in cList:
				itm = dsBw.ItemList[col]
				if itm.Group == 0:
					itm.Group = k+1
		print(f'LL = {lvList}\nDims = {dimList}')
		dsBw.AutoScaling = True
		dsBw.SortItems(False)		

	fChain = []
	dsCS = ds.ColumnSpecList
	for lv in lvList:
		fChain.append( [dsCS[k].Id for k in range(ds.Columns) if colKey[k]>lv*maxV] )
	return fChain

def GetFeatureChain(K):
	ds = vv.GetNumberTableView(True)
	colKey = [it.Value for it in ds.SqueezeRows(9, False)]
	dsBw = New.BarView(colKey).Show()
	for k in range(ds.Columns):
		dsBw.ItemList[k].Id = ds.ColumnSpecList[k].Id
	dsBw.SortItems(False)
	fList = [item.Id for item in dsBw.ItemList]
	dsBw.Close()
	fChain = []
	n = 3
	for k in range(K):
		fChain.append(fList[0:n])
		n += n
	return fChain

def NewFeatureChain2(dsList):
	fChain = None
	K = 8
	for nm in dsList:
		vv.Folder.OpenDataset(nm)
		fc = GetFeatureChain(N)
		fc = list( map(set, fc) )
		if fChain == None:
			fChain = fc
		else:
			fChain = [ fChain[k] | fc[k] for k in range(K) ]
	fChain = [list(f) for f in fChain]
	return fChain

# split the whole feature space by the column type, excluding the type 0.
def NewFeatureChain3():
	if not hasattr(pp, 'BodyList'):
		vv.Message('This service must be called from a feature-map!')
		vv.Return(0)
	tList = {b.Type for b in pp.BodyList if b.Type>0}
	fChain = []
	for k, t in enumerate(tList):
		fChain.append( [b.Id for b in pp.BodyList if b.Type==t] )
	for k, f in enumerate(fChain):
		print(f'{k}: {len(f)}')
	return fChain

def SaveFeatureChain(fChain, keyName):
	vv.GroupManager.SetGroupLabels(keyName, ['&'.join(x) for x in fChain])

def LoadFeatureChain(keyName):
	fChain = vv.GroupManager.GetGroupLabels(keyName)
	if fChain == None:
		print(f'Cannot find group "{keyName}"!')
		return None
	return [f.split('&') for f in fChain]

def Do_Stratify(fChain, ex0=4.0, ppl=0.05):
	global dsMap
	ds = vv.GetNumberTableView(True).ApplyFilter(vv.Map.Filter)
	mD = 3 if dsMap3D else 2
	dsMap = New.NumberTable(ds, mD*len(fChain))
	print(f' ______________\tFeatures\tTime _____________')
	tt = NewTsneMachine(ds,'EuclideanMetric', ex0=ex0, ppl=ppl)
	for k, fs in enumerate(fChain):
		ds2 = ds.SelectColumnsById(fs)
		tt.SetTrainingData(ds2)
		tm = RunTsne(tt)
		dsMap.ColumnSpecList[k*mD].Name = '|'.join(fs)
		AddMap2Dataset(dsMap,tt.BodyList,tt.Is3D,k*mD,k,f',\t{ds2.Columns}\t{tm:.1f}s')
	tt.Close()
	MergeDatasetMaps('Alg: Stratify')

#----------------------------------------------------

with CheckTime('Total Time'):
	#Do_ByViewpoint(flag=CENTERS_VP)
	#Do_ByViewpoint(flag=HIGHLIGHT_VP)
	#Do_ByViewpoint(flag=INTPO_VP, K=32)
	#Do_Cascading()
	Do_Stratify(fChain, 4.0, 0.05)
	#ShowMapDataset()

'''
fChain = NewFeatureChain(12, 0.9, 0.05,  showChain=True)
fChain = NewFeatureChain(LL =  [0.9, 0.825, 0.75, 0.675, 0.6, 0.525, 0.45, 0.25],  showChain=True)
SaveFeatureChain(fChain, 'FeatureChain1')
dsList = ['Perivascular',  'TCellBreast', 'BreastCancer', 'Myeloid', 'Vascular-C']
fChain = NewFeatureChain2(dsList)
SaveFeatureChain(fChain, 'FeatureChain')
fChain = NewFeatureChain3()

fChain = LoadFeatureChain('FeatureChain')

ConcatMapList(['A0', 'A1', 'A2', 'A2', 'A2'])
ConcatSnapshots()

ShowMapDataset()
MergeDatasetMaps()
dsMap = pp.GetNumberTable()
'''


