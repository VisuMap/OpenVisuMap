# Import a VCF (variation call format) file into a heatmap view.
# 
# The following site offers some sample datasets:
#
#  https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/hd_genotype_chip/
#  https://www.internationalgenome.org/data-portal/sample/HG00138
#
import clr, gzip, math
import numpy as np
vv.Import('AtlasHelp.pyn')

def ClusterBySNP():
	bList = vv.Dataset.BodyList
	SNPtoType = {'AG':0,'AC':1,'AT':2,'GC':3,'GT':4,'CT':5,	'GA':0,'CA':1,'TA':2,'CG':3,'TG':4,'TC':5}
	for b in bList:
		b.Type = SNPtoType[ b.Name.split('|')[0] ] 
	vv.Map.RedrawAll()

def ClusterByKeys(bList, keys):
	pMin, pMax = np.min(keys), np.max(keys)
	stepSize = (pMax - pMin)/32.0
	for idx, b in enumerate(bList):
		b.Type = int(math.floor((keys[idx] - pMin)/stepSize))
	vv.Map.RedrawAll()

def ClusterByPositions():
	bList = vv.Dataset.BodyList
	pList = np.zeros(bList.Count, dtype=np.float64)
	for idx, b in enumerate(bList):
		pList[idx] = np.float64(b.Name.split('|')[2])
	ClusterByKeys(bList, pList)


def ClusterByInfo(fieldName):
	bList = vv.Dataset.BodyList
	pList = np.zeros(bList.Count, dtype=np.float64)
	L = len(fieldName)
	for idx, b in enumerate(bList):
		nm = b.Name
		i = nm.index(fieldName) + L
		j = nm.index(';', i)
		pList[idx] = np.float64(nm[i:j])
	ClusterByKeys(bList, pList)

'''
ClusterByInfo('AC=')
ClusterByInfo('SAS_AF=')

'''

def ImportVCF(maxRows=0, skipSize=0):
	fn = PromptFile("VCF GZ Files|*.vcf.gz|VCF Files|*.vcf")
	vf = gzip.open(fn,'rt') if fn.endswith('.gz') else open(fn, 'rt')
	rows = 0
	matrix = []
	rowIds = []
	rowNames = []
	lineCount = 0
	personId = []

	for line in vf:
		lineCount += 1
		if lineCount%100_000 == 0:
			vv.Echo("Lines processed: %d, imported: %d"%(lineCount, rows))
		if line.startswith('#'): 
			if line.startswith('#CHROM'):
				personId = line.split()[9:]
				vv.Echo("Samples: " + str(len(personId)))
			continue
		if (skipSize != 0) and (lineCount % skipSize != 0):
			continue
		fs = line.split()
		if len(fs) < 10: 
			continue

		chrom = fs[0]
		pos = fs[1]
		rid = fs[2]
		refA = fs[3]
		altA = fs[4]
		quality = fs[5]
		filter = fs[6]	
		info = fs[7]
		fmt = fs[8]

		# skip also lines with too low allele count
		skipLine = False
		for ifs in info.split(';'):
			if ifs.startswith('AC=') and ifs[3:].isnumeric():
				skipLine = (int(ifs[3:]) <= 3)
				break
		if skipLine:
			continue
		if refA not in "ACGT" or altA not in "ACGT": 
			continue
		if filter not in ['PASS', '.']: 
			continue

		gtStrings = fs[9:]
		gtArray = np.zeros(len(gtStrings), dtype = np.int8)
		for idx, gType in enumerate(gtStrings):
			if (gType == './.') or (len(gType)<3):
				gtArray[idx]=-1
				continue 
			a0 = gType[0] # Get the first allele (as a string)
			a1 = gType[2]
			if (a0=='1' and a1=='1'): 
				gtArray[idx]=2
			elif ((a0=='0' and a1=='1') or (a0=='1' and a1=='0')):
				gtArray[idx]=1   
			elif (a0=='0' and a1=='0'):
				continue
			else:
				break

		rows += 1
		matrix.append(gtArray)
		rowIds.append(rid)
		rowNames.append(refA+altA+'|'+chrom+'|'+pos+'|'+info+'|'+fmt)
		if (maxRows != 0) and (rows>=maxRows):
			break

	vf.close()
	if rows == 0:
		vv.Message("No data imported")
		quit()

	matrix = np.ascontiguousarray(np.array(matrix))
	nt = mm.ToTable(np.float64(matrix))
	for row, b in enumerate(nt.RowSpecList):
		if rowIds[row] == '.':
			b.Id = 'p_' + pos
		else:
			b.Id += '_' + rowIds[row]
		b.Name = rowNames[row]
	if len(personId) == nt.Columns:
		csList = nt.ColumnSpecList
		for col, id in enumerate(personId):
			csList[col].Id = id
	nt.ShowHeatMap()


ImportVCF(maxRows=23000, skipSize=100)
