# functions to import and process pdb/cif files.
vv.Import('SeqVis.pyn')

PDB_CACHE = 'C:/temp/PdbCache'
CHAIN_CACHE = 'C:/temp/ChainCache'

# get the path for the cached (PDB) CIF file.
def PdbCacheFile(pId):
	if len(pId)<4:
		raise Exception(f'Invalid protein ID: {pId}')
	return f'{PDB_CACHE}/{pId[:4]}.cif'

# get cache file path for a poliptide chain.
def ChainCacheFile(chId):
	if len(chId)<4:
		raise Exception(f'Invalid protein chain id {chId}')
	return f'{CHAIN_CACHE}/{chId}.pmc'

def CheckCacheDir():
	from os.path import exists
	if not exists(PDB_CACHE) or not exists(CHAIN_CACHE):
		vv.Message(f'Cache directories not setup: {PDB_CACHE} and {CHAIN_CACHE}')
		vv.Return()

def ShowPDB(pId, rp=3, chainNames=None, includeHA=True, hidIntp=False,
		setChainId=False,	typeByChainIdx=False, glyphSize=1.0, glyphOpacity=0.75):

	if includeHA or chainNames==None or len(chainNames)>1:
		localPath, bsList, bsList2, pdbTitle = LoadCifData(pId, chainNames=chainNames)
	else:
		localPath, bsList, bsList2, pdbTitle = None, LoadChain(pId), None, "???"

	bsList = Interpolate(bsList, rp, hidIntp=hidIntp)
	
	if setChainId:
		ds = vv.Dataset
		chId = pId[:4]
		chName2Id = {ds.StringAt(b.Id, 4):b.Id for b in ds.BodyList if b.Id.startswith(chId)}
		for b in bsList:
			chName = b.Name.split('.')[2]
			# notice some chains maybe exact repeats so that they not in the dataset table, but
			# accounted in the Repeats columns. 
			if chName in chName2Id:
				b.Id = chName2Id[chName]
			else:
				b.Id = chId + chName 

	#Set the chain name index as body type, which was holding the enitity id.
	if typeByChainIdx:
		chName2Type = {}
		for b in bsList:
			chName = b.Name.split('.')[2]
			if not chName in chName2Type:
				chName2Type[chName] = len(chName2Type)
			b.Type = chName2Type[chName]

	cs.NormalizeChain(bsList, -1, False)

	if includeHA:
		bsList.AddRange(bsList2)

	info = MapInfo()
	info.pId = pId
	info.pLen = bsList.Count
	info.PT = SimplifyTitle(pdbTitle)
	info.Set('HA', includeHA)	
	mp = ShowBodyList(bsList, gSize=glyphSize, gOpacity=glyphOpacity, info=info)
	mp.Title = f'{pId}, Len:{bsList.Count}:  {info.PT}'
	return mp


def ShowChain(cId, gsize=2.1, gopacity=0.75, hsize=3, intRp=5):
	bList = LoadChain(cId)
	bList = Interpolate1Chain(bList, rp=intRp)
	for b in bList: b.Hidden = (b.Id[0] == 'i')
	cs.NormalizeChain(bList)
	return ShowBodyList(bList, gSize=gsize, gOpacity=gopacity, hSize=hsize)

def ShowProteinList(pList, includeHA, atName=None, gsize=1.0, gopacity=0.75, intRp=3):
	mapStore = NewMapStore(atName)
	if mapStore != None:
		mapStore.atlas.Description = f'DS:{vv.Dataset.Name}'
	for k, pId in enumerate(pList):
		vv.Title = f'Loading {pId}: {k+1}-th of {len(pList)}'
		chainNames = GetChainName(pId)
		mp = ShowPDB(pId, chainNames=chainNames, includeHA=includeHA, 
				rp=intRp, glyphSize=gsize, glyphOpacity=gopacity)
		if mapStore != None:	
			mapStore.AddMap('D3dRender')
		else:
			cs.NormalizeChain(mp.BodyList, chType=-1, hidIntp=True)
			mp.NormalizeView()
	if mapStore != None:
		ma = mapStore.atlas
		for item in ma.Items: 
			item.IconWidth = 250
		ma.Show()
		ma.ArrangeItems(False)
		ma.OnItemsSelected = ''
		del mapStore

def GetChainName(pId):
	rowIdx = vv.Dataset.BodyIndexForId(pId)
	if rowIdx >= 0:
		return [ vv.Dataset.StringAt(rowIdx, 4) ]
	else:
		vv.Message(f'Cannot find chain {pId} in current dataset.')
		return None

def UnFoldProteinList(pList, epochs=1000, includeHA=False, wholeComplex=False, 
		samplingDist=0,  ppl=0.1, initExag=5.0, finalExag=1.0, atName=None, 
		stretch=0, clusterStretch=0.5, expandFactor=1.0, iconWidth=50, glyphSize=2.0):
	t0 = time.time()
	if wholeComplex:
		# Remove all duplicates.
		selected = set()
		pList2 = []
		for p in pList:
			if p[:4] not in selected:
				pList2.append(p)
				selected.add(p[:4])
		pList = pList2

	if samplingDist > 0:
		pList = cs.FlatSampling(pList, samplingDist)
		vv.Title = f'Sampled {len(pList)} chains!'
	else:
		vv.Title = 'Sampled all chains'

	if vv.ModifierKeys.ControlPressed:
		vv.SelectedItems = pList
		return
	
	mapStore = NewMapStore(atName)	
	rFreq = 10 if mapStore == None else 0
	mds = NewMds(nt=None, epochs=epochs, is3D=False, refreshFreq=rFreq, repeats=0, metric='EuclideanMetric',
		ppl=ppl, initExag=initExag, finalExag=finalExag, glyphSet=SeqMap_GLYPHSET, glyphOpacity=1.0)	
	mds.GlyphSize = 0.75 if atName==None else glyphSize
	mds.AutoNormalizing = False
	mds.AutoScalingTsne = False

	try:
		for n, pId in enumerate(pList):
			chainNames = None if wholeComplex else GetChainName(pId)
			localPath, bList, bList2, pdbTitle = LoadCifData(pId, chainNames=chainNames)
			seqLen = bList.Count

			if not wholeComplex:
				for b in bList:
					b.Hidden = False
				cs.NormalizeChain(bList, 184)						
			bList = Interpolate(bList, rp=3)
			if includeHA:
				bList.AddRange(bList2)
			nt = Augment2Table(bList, stretch=stretch, clusterStretch=clusterStretch, expandFactor=expandFactor)
			if nt.Rows < 8:
				continue	

			info = MapInfo()
			info.SF = stretch
			info.CF = expandFactor
			info.pId = pId
			info.pLen = bList.Count
			info.PT = SimplifyTitle(pdbTitle)
			info.DS = f'DS:{vv.Dataset.Name}'
			info.Set('HA', includeHA)
			if chainNames != None:
				info.Set('CNs', '|'.join(chainNames) )
			mds.SetTrainingData(nt)
			vv.Title = f'Unfolding {pId}/{seqLen:,}: {n+1}-th of {len(pList)}'

			# Mark the head red.
			bList = mds.BodyList
			bList[0].Type = SeqMap_HEAD
			for k in range(1, bList.Count-1):		
				if bList[k].Name.split('.')[2] != bList[k+1].Name.split('.')[2]:
					bList[k].Type = SeqMap_TAIL
					bList[k+1].Type = SeqMap_HEAD
			bList[bList.Count-1].Type = SeqMap_TAIL

			RunMds(mds, info=info, repeats=0)

			if mapStore != None:
				mapStore.AddRawMap(pId, mds.BodyList, scale=10)
			else:
				mds.NormalizeView()
				mds.ShowSnapshot()
	except Exception as e:
		vv.Message(str(e))
	if mapStore != None:
		mds.Close()
		ma = mapStore.atlas
		MatchProteinMap(ma, iconWidth)
		info.Set('TM', round(time.time()-t0, 3))
		ma.Description = info.ToStr()
		ma.Show()
		ma.DataChanged = True # since the Show() clears the DataChanged flag.
		del mapStore

# CreateProteinMaps() is a fast version of UnFoldProteinList(), it is limited to sequences with less than 23K PP.
def CreateProteinMaps(pList, samplingDist, atlasName, tP):
	global ctrPressed

	epochs, intRp, stretch, ppl, initE, finalE = tP
	if samplingDist > 0:
		pList = cs.FlatSampling(pList, samplingDist)
		vv.Title = f'Sampled {len(pList)} chains!'
		if ctrPressed:
			vv.SelectedItems = pList
			return

	maxRows = MaxRows(vv.Dataset, pList, intRp)
	tsne = FastTsne(maxRows, 4, 2, epochs, ppl, initE, finalE)
	L = len(pList)
	if L > 10:
		mapStore = AtlasMapStore(atlasName)
		if L > 1000:
			mapStore.hideItems = True
	else:
		mapStore = None
	t0 = time.time()
	for k, pId in enumerate(pList):
		bList = LoadChain(pId)
		bList = Interpolate1Chain(bList, intRp)
		nt = cs.AugmentByStretch(bList, stretch, intRp)
		nt = tsne.Fit(nt)
		if nt == None:
			continue
		bList = nt.ToBodyList()
		if mapStore == None:
			map = New.MapSnapshot(bList)
			ConfigSeqMap(map, pId, gsize=1.0)
			cs.FitByPCA(map, 15.0).Show()
		else:
			mapStore.AddRawMap(pId, bList, scale=60)
			if (k+1)%50==0: 
				vv.Title = f'2D Fitted {pId}/{bList.Count}: {k+1}-th of {L}'
		vv.DoEvents()
		if vv.GuiManager.StopFlag:
			break

	if mapStore != None:
		info = MapInfo()
		info.Set('TM', round(time.time()-t0, 3))
		info.Set('tP', tP)
		ma = mapStore.atlas
		ma.Show()
		MatchProteinMap(ma, 50)
		ma.Description = info.ToStr()
		del mapStore

def SimplifyTitle(title):
	return title.replace(':', '..').replace(';', '.,')

def LoadCifData(pId, chainNames=None):
	localPath = pId if pId.endswith('.cif') else Download3DInfo(pId[:4])
	bsList = cs.LoadCif(localPath, chainNames)
	if bsList == None:
		return None, None, None, ''
	else:
		return localPath, bsList, cs.GetHeteroChains(), cs.GetTitle()

def OpenCifFile(pId):
	vv.StartProcess("vi", PdbCacheFile(pId))

def Augment2Table(bList, stretch, clusterStretch=1.0, expandFactor=1.0):

	if expandFactor != 1.0:
		bList = New.BodyListClone(bList)
		bList = cs.LocalExpand(bList, expandFactor)
	nt = New.NumberTable(bList,3)

	if stretch == 0 and clusterStretch == 0:
		return nt
	if nt.Rows <= 1:
		return nt	

	if clusterStretch == 0:
		nt.AddColumns(1)
	else:
		nt.AddColumns(4)

	M = nt.Matrix
	rsList = nt.RowSpecList
	# get the number of interpolation points, ipp, which is normally 8
	dx = 0
	for ipp in range(1, min(64, rsList.Count)):		
		if rsList[ipp].Id[0] == 'A':
			dx = 0.1*stretch/ipp
			break
	if dx == 0:
		return nt

	meanV = {}
	meanCnt = {}
	for row, rs in enumerate(rsList):
		if rs.Type not in meanCnt:
			meanCnt[rs.Type] = 0
			meanV[rs.Type] = [0, 0, 0]
		meanCnt[rs.Type] += 1
		V, R = meanV[rs.Type], M[row]
		for dim in range(3):
			V[dim] += R[dim]

	for row, rs in enumerate(rsList):
		if (row==0) or (rs.Type != rsList[row-1].Type): 
			offset = -0.5*meanCnt[rs.Type]*dx
		# hetero atoms don't participate in the unfold stretching
		if rs.Id[0] == 'H': continue
		#if rs.Name[0] == 'r': continue
		M[row][3] += offset
		offset += dx

	if clusterStretch != 0:
		for t in meanCnt:
			n, V = meanCnt[t], meanV[t]
			for dim in range(3):
				V[dim] = clusterStretch * V[dim]/n
		for row, rs in enumerate(rsList):
			V, R = meanV[rs.Type], M[row]
			for dim in range(3):
				R[4+dim] = V[dim]
	return nt

def Download3DInfo(pId):
	from os.path import exists
	#from urllib.request import urlretrieve
	import requests
	localPath = PdbCacheFile(pId)	
	if not exists(localPath):
		CheckCacheDir()
		remotePath = f'https://files.rcsb.org/download/{pId[:4]}.cif'
		#urlretrieve(remotePath, localPath)
		#print(f'Downloading {pId}...')
		request = requests.get(remotePath, timeout=30, stream=True)
		with open(localPath, 'wb') as f:
			for chunk in request.iter_content(1024 * 1024):
				f.write(chunk)
	return localPath


def HideInterpolates():
	for b in pp.BodyList:
		if b.Id.startswith('i'):
			b.Hidden = True
	pp.TheForm.HiddenBodySize = 4
	pp.RedrawAll()

def ShowHelix():
	vv.SelectedItems = [b.Id for b in pp.BodyList if b.Name.endswith('.h')]

def ShowBetaSheet():
	vv.SelectedItems = [b.Id for b in pp.BodyList if b.Name.endswith('.b')]


def LoadChain(pId):
	from os.path import exists
	cacheFile = ChainCacheFile(pId)
	if not exists(cacheFile):
		UnpackChain(pId[:4])
	return cs.LoadChain3D(cacheFile)

def LoadSeq(pId):
	from os.path import exists
	cacheFile = ChainCacheFile(pId)
	if exists(cacheFile):
		return cs.LoadChainSeq(cacheFile)
	else:
		seq = []
		bList = LoadChain(pId)
		c = bList[0].Name[0]
		idx = 2 if ( c=='r' or c=='d') else 0
		for b in bList:
			c = b.Name[idx]
			if idx == 2: 
				c = c.lower()
			seq.append(c)
		return ''.join(seq)

def ChainName(body):
	return body.Name.split('.')[2]

def Interpolate(bList, rp=3, hidIntp=False):
	EPS = 0.085
	bs = New.BodyList()
	k0 = 0
	t0 = ChainName(bList[0])
	chIdx  = 0
	for k in range(bList.Count+1):		
		if (k == bList.Count) or (ChainName(bList[k]) != t0):
			P0 = bList.GetRange(k0, k-k0)
			P1 = cs.Interpolate3D(P0, rp, EPS, bs.Count, chIdx)
			chIdx += 1
			#PyInterpolate(P0, P1,  2**rp)
			bs.AddRange(P1)
			if k < bList.Count:
				k0 = k
				t0 = ChainName(bList[k0])
	if hidIntp:
		for b in bs:
			b.Hidden = b.Id.startswith('i')
	return bs

def Interpolate1Chain(bList, rp=3, hidIntp=False):
	EPS = 0.085
	marked = bList[0].Type == SeqMap_HEAD
	if marked:
		bList[0].Type = bList[1].Type
		bList[bList.Count-1].Type = bList[1].Type			
	bList = cs.Interpolate3D(bList, rp, EPS, bList.Count, 0)
	if marked:
		bList[0].Type = SeqMap_HEAD
		bList[bList.Count-1].Type = SeqMap_TAIL
	if hidIntp:
		for b in bList:
			b.Hidden = b.Id.startswith('i')
	return bList

def UnFoldMap(pMap, epochs=1000, ppl=0.1, staged=False, repeats=1, stretch=0, clusterStretch=1.0, expandFactor=1.0, initExag=10.0, finalExag=1.0, is3D=False):
	bList = pMap.BodyListEnabled()
	nt = Augment2Table(bList, stretch=stretch, clusterStretch=clusterStretch, expandFactor=expandFactor)
	mds = NewMds(nt, is3D=is3D, glyphSet=pMap.GlyphSet, initExag=initExag, finalExag=finalExag,
		epochs=epochs, ppl=ppl, staged=staged)
	info = MapInfo(pMap.Description).SetMds(mds)
	info.SF = stretch
	info.CF = expandFactor  # Local expanding factor
	winTitle = pMap.Title
	mds.GlyphSize = 0.5
	RunMds(mds, repeats=repeats, info=info)
	vv.LastView.Title = winTitle
	if repeats != 0:
		mds.Close()

# Extract chains from PDB complex and store then in current table. Heter-atoms and singltons will be ignored.
def LoadChains(pId):
	ds = vv.Dataset
	if (ds.Columns != 5) or (ds.ColumnSpecList[4].Id != 'ChainName'):
		vv.Message('Current dataset has invalid format: pid;repeats;seq;len;chainName')
		return None, None, None
	try:
		_, bList, _, pdbTitle = LoadCifData(pId)
	except Exception as ex :
		return None, None, None

	if (bList == None) or (len(bList) == 0):
		return None, None, None

	chainList = cs.SplitByChainName(bList)
	totalLength = sum([ch.Count for ch in chainList])
	chainList = [ ch for ch in chainList if ch.Count>1 ]
	chIdx = None
	for chIdx, ch in enumerate(chainList):
		b = ch[0]
		entityId = b.Type + 1
		fs = b.Name.split('.')
		chName = fs[2]
		if fs[0] == 'r':	
			ppType = 99
			chType = 'r'
		elif fs[0] == 'd':
			ppType = 97
			chType = 'd'
		else:
			ppType = 0
			chType = 'A'
		pSeq = cs.ToSequence(ch)
		seqLen = len(pSeq)
		body = ds.AddRow(pId + '_' + str(chIdx), None,  ppType, [chType, str(entityId), pSeq, str(seqLen), chName])
		if body == None:
			raise Exception('Failed: '+vv.LastError)

	return chIdx, totalLength, pdbTitle

# Unpack all chains in a PDB directory and store them in current dataset.
# A summary table about each protein will displayed.
def LoadAllChains(pList=None):
	import os
	ds = vv.Dataset
	if (ds.Columns != 5) or (ds.ColumnSpecList[4].Id != 'ChainName'):
		vv.Message('Current dataset has invalid format: pid;repeats;seq;len;chainName')
		return
	if pList == None:
		pList = [f[:4] for f in os.listdir(PDB_CACHE) if f.endswith('.cif')]	
	chCount = 0
	pTable = New.FreeTable()
	pTable.AddColumn('Chains', True)
	pTable.AddColumn('Size', True)
	pTable.AddColumn('Title', False)

	print(f'Importing {len(pList)} proteins')
	loaded, skipped = [], []
	for k, pId in enumerate(pList):
		if (k+1)%50 == 0:
			print(f'{k+1}: {pId} {chCount} chains')
		chCnt, totalLen, title = LoadChains(pId)
		if chCnt == None:
			skipped.append(pId)
			continue
		chCount += chCnt
		loaded.append(pId)
		pTable.AddRow(pId, 0, [str(chCnt), str(totalLen), title])
		vv.DoEvents()
	ds.CommitChanges()
	return pTable, loaded, skipped

def SaveChain(chId, chain):
	cs.SaveChain(ChainCacheFile(chId), chain)

cachedNm2Id = None

def UnpackChain(pId):
	global cachedNm2Id
	ds = vv.Dataset

	if (cachedNm2Id == None) or (cachedNm2Id['DS_Name'] != ds.Name) or (len(cachedNm2Id)-1 != ds.Rows):
		# nm2id converts a chain-name to chain-id using the current dataset.
		nm2id = {}
		for b in ds.BodyList:
			nm = ds.StringAt(b.Id, 4)
			nm2id[b.Id[:4]+'_'+nm] = b.Id
		cachedNm2Id = nm2id
		cachedNm2Id['DS_Name'] = ds.Name
	else:
		nm2id = cachedNm2Id

	_, bList, _, pdbTitle = LoadCifData(pId)
	if bList == None:
		return
	for ch in cs.SplitByChainName(bList):
		chIdName = pId + '_' + ChainName(ch[0])
		vv.DoEvents()
		if chIdName in nm2id:
			SaveChain(nm2id[chIdName], ch)

'''
UnpackChain('2JU0')
'''

def PreloadPDB(sList):
	from os.path import exists
	pList = sList.split(',')
	print(f'Preloading {len(pList)} pIds...')
	pList = list(set([p[:4] for p in pList]))
	print(f'Preloading {len(pList)} files...')
	loaded = []
	errs = 0
	cnt = 0
	for k, pId in enumerate(pList):
		if (cnt+1)%50 == 0: print(f'Downloading {k}-th cif {pId}')
		if not exists(PdbCacheFile(pId)):
			try:
				Download3DInfo(pId)
				vv.DoEvents()
				loaded.append(pId)
				cnt += 1
			except Exception as e:
				errs += 1
				if (errs < 5):
					print(f'EXCEPTION ({k}): ', pId, str(e))
					raise e
		else:
			loaded.append(pId)			
	print(f'Downloaded {len(loaded)} PDB files')
	return loaded

def InitDatabase(dsName, description):
	dsName = vv.Folder.NewDataset(dsName, description).Name
	vv.Folder.OpenDataset(dsName)
	vv.Map.GlyphSet = PMap_GLYPHSET
	ds = vv.Dataset
	ds.AddColumn('ChainType', 0, '', 0)
	ds.AddColumn('EntityId', 1, '0', 1)
	ds.AddColumn('ProteinSeq', 0, '', 2)
	ds.AddColumn('SeqLen', 1, '0', 3)
	ds.AddColumn('ChainName', 0, '', 4)
	ds.CommitChanges()

def MergeTableToDataset(tb, dsName):
	oldDsName = vv.Dataset.Name
	ds = vv.Folder.OpenDataset(dsName)
	if ds == None:
		vv.Folder.NewDataset(dsName, '')
		ds = vv.Folder.OpenDataset(dsName)
		ds.AddColumn('Chains', 1, '0', 0)
		ds.AddColumn('Size', 1, '0', 1)
		ds.AddColumn('Title', 0, '', 2)
		ds.CommitChanges()
	for row in range(tb.Rows):
		rowId = tb.RowSpecList[row].Id
		rowIdx = ds.IndexOfRow(rowId)
		R = tb.Matrix[row]
		if rowIdx < 0:
			ds.AddRow(rowId, '', 0, R)
		else:
			ds.SetDataAt(rowIdx, 0, R[0])
			ds.SetDataAt(rowIdx, 1, R[1])
			ds.SetDataAt(rowIdx, 2, R[2])
	ds.CommitChanges()
	vv.Folder.OpenDataset(oldDsName)

# import a protein list into a new dataset table.
def ImportPDBList(sList, dsName, dsDescription=''):
	pList = PreloadPDB(sList)
	InitDatabase(dsName, dsDescription)
	infoTable, loaded, skipped = LoadAllChains(pList)
	MergeTableToDataset(infoTable, "P-Info")
	vv.Map.Randomize()
	vv.Map.Redraw()
	if len(skipped) > 0:
		skList = ','.join(skipped[:100])		
		msg = f'Skipped {len(skipped)} cif files: {skList}'
		print(msg)
		vv.Message(msg)

def GetAAGroup(idx=0):
	aaHydrophobic = 'AVILMFYW'
	aaPolarUncharged = 'STNQ'
	aaSpecial = 'CGP'
	aaSpC = 'C'
	aaSpG = 'G'
	aaSpP = 'P'
	aaNoPolar = 'AGILMPV'
	aaCarboxyl = 'DE'
	aaAmine = 'RHK'
	aaAromatic = 'FWY'
	aaHydroxyl = 'STY'

	match idx:
		case 0:
			return 'AVILMFYW|STNQ|CGP|RHK|DE'
		case 1:
			return '|'.join( [ aaHydrophobic, aaPolarUncharged,  aaSpecial, aaNoPolar, aaCarboxyl, aaAmine, aaAromatic, aaHydroxyl] )
		case 11:
			return [ aaHydrophobic, aaPolarUncharged,  aaSpecial, aaNoPolar, aaCarboxyl, aaAmine, aaAromatic, aaHydroxyl]
		case 2:
			return aaHydrophobic
		case 3:
			return aaAromatic
		case 4:
			from itertools import combinations
			#return ['|'.join(g) for g in combinations(list('CGPDEFWY'), 3)]
			return ['|'.join(g) for g in combinations(list('AVILMFYW'), 3)]
		case 10:
			return 'AVILMFYW|STNQ|CGP|RHK|DE|aut|cg'
		case 12:
			return 'FL|S|Y|CW|L|P|HQ|R|IM|T|N|K|S|R|V|A|D|E|G|aut|cg'
		case 13:
			return 'FLSYCW|LPHQR|IMTNKSR|VADEG|aut|cg'
		case 14:
			return 'IMTNKSR|aut|cg'
		case 9:
			return '|'.join('AVILMFYWSTNQCGPRHKDE')
		case 20:
			return 'AVILMFYW|STNQ|CGP|RHK|DE|ctu'
		case 21:
			return 'AVILMFYW|STNQ|CGP|RHK|DE|c|g|u|a'
		case 22:
			return '|'.join('AVILMFYWSTNQCGPRHKDE') + '|c|g|u|a'


ss2 = New.CsObject('''

	Dictionary<char, int> ppIdx = null;

	public void Init_ppIdx(string pepList) {
		ppIdx = Enumerable.Range(0, pepList.Length).ToDictionary(k=>pepList[k], k=>k);
	}

	public void ToPepCount(string seq, double[] R) {
		foreach( char c in seq ) {
			int idx = ppIdx.ContainsKey(c) ? ppIdx[c] : ppIdx['x'];
			R[idx] += 1.0;
		}
	}
	
	public string GetPepSeq(List<IBody> bList) {
		StringBuilder sb = new StringBuilder();
		foreach(var b in bList) {
			char c = b.Name[0];
			if ( c.Equals('r') || c.Equals('d') )
				c = char.ToLower( b.Name[2] );
			sb.Append(c);
		}
		return sb.ToString();
	}

''')

def ToChainList(pList):
	pSet = set(pList)
	pChains = {}
	for pId in vv.AllItems:
		pId4 = pId[:4]
		if pId4 in pSet:
			if pId4 not in pChains:
				pChains[pId4] = []
			pChains[pId4].append(pId)
	return pChains

def ShowPepCounts(pList):
	pepList = 'ARNDCEQGHILKMFPSTWYVaucgtx'
	nt = New.NumberTable(len(pList), len(pepList))
	for k in range(nt.Columns):
		nt.ColumnSpecList[k].Id = pepList[k]
	for row, pId in enumerate(pList):
		nt.RowSpecList[row].Id = pId
	ss2.Init_ppIdx(pepList)
	chainList = ToChainList(pList)
	chainKeys = set(chainList.keys())
	for row, pId in enumerate(pList):
		if pId in chainKeys:
			R = nt.Matrix[row]
			for chId in chainList[pId]:
				ss2.ToPepCount(LoadSeq(chId), R)
		#bList = cs.LoadCif(f'{PDB_CACHE}/{pId}.cif', None)
		#ss2.ToPepCount(ss2.GetPepSeq(bList), nt.Matrix[row])
		if row%100 == 0:
			print(f'{row}: {pId}')
			vv.DoEvents()
	nt.ShowHeatMap()

'''
--- Steps to import a list of PDB id into VisuMap: ---
sList = vv.GuiManager.GetClipboard()
print(len(sList.split(',')))
ImportPDBList(sList, 'TT')

for dn in dnList:
	vv.Folder.OpenDataset(dn+str(1))
	vv.Dataset.Name = dn

	sList = set([p[:4] for p in vv.AllItems])
	sList = ','.join(list(sList))
	ImportPDBList(sList, dn)
	MainMain('P-Map')


# remove all chain cache files of a pList:
import os
pList = [b.Id for b in vv.Dataset.BodyListEnabled()]
pList = set([p[:4] for p in pList])
print(len(pList))
fList = []
for f in os.listdir(CHAIN_CACHE):
	if f[:4] in pList:
		fList.append(f)
for f in fList:
	os.remove(f'{CHAIN_CACHE}/{f}')

sList = ','.join([f[:4] for f in os.listdir(PDB_CACHE)])
sList = ','.join(pList)
print(len(sList))
ImportPDBList(sList, 'PSymmetry10K')

# Extract a chain list for each dataset:
dnList = list(vv.Folder.DatasetNameList)[1:]
dsInfo = New.FreeTable(len(dnList), 3)
for k, dn in enumerate(dnList):
	ds = vv.Folder.ReadDataset(dn)
	pSet = set([b.Id[:4] for b in ds.BodyList])
	pList = list(pSet)
	dsInfo.Matrix[k][0] = dn
	dsInfo.Matrix[k][1] = ','.join(pList)
	dsInfo.Matrix[k][2] = str( len(pList) )
New.DataDetails(dsInfo).Show()

dsList = []
ds = vv.Dataset
for k in range(ds.Rows):
	dsList.append( (ds.StringAt(k, 0), ds.StringAt(k, 1)) )
dsList = dsList[5:]
for dn, sList in dsList:
	print(dn, len(sList.split(',')))
	ImportPDBList(sList, dn)

ds = vv.Folder.ReadDataset("P-Info")
pList = [b.Id for b in ds.BodyList]
ShowPepCounts(pList)

'''
