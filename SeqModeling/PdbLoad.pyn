# functions to import and process pdb/cif files.
vv.Import('SeqVis.pyn')

PDB_CACHE = 'c:/temp/PdbCache'
CHAIN_CACHE = 'C:/temp/ChainCache'

# get the path for the cached (PDB) CIF file.
def PdbCacheFile(pId):
	if len(pId)<4:
		raise Exception('Invalid protein ID')
	return f'{PDB_CACHE}/{pId[:4]}.cif'

# get cache file path for a poliptide chain.
def ChainCacheFile(chId):
	if len(chId)<4:
		raise Exception(f'Invalid protein chain id {chId}')
	return f'{CHAIN_CACHE}/{chId}.pmc'

def CheckCacheDir():
	from os.path import exists
	if not exists(PDB_CACHE) or not exists(CHAIN_CACHE):
		vv.Message(f'Cache directories not setup: {PDB_CACHE} and {CHAIN_CACHE}')
		vv.Return()

csLoad = New.CsObject('''
public List<IBody> LoadChain(string cacheFile) {
	string[] lines = File.ReadAllLines(cacheFile);	
	IBody[] bList = new IBody[lines.Length];	
	MT.Loop(0, lines.Length, lineIdx=>{
			string line = lines[lineIdx];
			if (line == null) 
				return;
			string[] fs = line.Split('|');
			Body b = new Body(fs[0]);
			b.Name = fs[1];
			b.Type = short.Parse(fs[2]);
			b.X = float.Parse(fs[3]);
			b.Y = float.Parse(fs[4]);
			b.Z = float.Parse(fs[5]);
			bList[lineIdx] = b;
	});
	return bList.ToList();
}

public string LoadSeq(string cacheFile) {
	StringBuilder sb = new StringBuilder();
	using( TextReader tr = new StreamReader(cacheFile) ) {
		while(true) {
			string line = tr.ReadLine();
			if (line == null) 
				break;
			int idx = line.IndexOf('|');
			sb.Append(line[idx+1]);
		}
	}
	return sb.ToString();
}
''')

def ShowPDB(pId, rp=3, eps=0.1, chainNames=None, includeHA=True, 
		setChainId=False,	smtRatio=0, glyphSize=1.0, glyphOpacity=0.75):
	localPath, bsList, bsList2, pdbTitle = LoadCifData(pId, chainNames=chainNames)
	bsList = Interpolate(bsList, rp, eps, smtRatio=smtRatio)

	bsList[0].Type = 171
	for k in range(1, bsList.Count-1):		
		if bsList[k].Name.split('.')[2] != bsList[k+1].Name.split('.')[2]:
			bsList[k].Type = 155
			bsList[k+1].Type = 171
	bsList[bsList.Count-1].Type = 155

	if includeHA:
		bsList.AddRange(bsList2)

	if setChainId:
		ds = vv.Dataset
		ch2pId = {}
		pId4 = pId[:4]
		for k in range(ds.Rows):
			id = ds.BodyList[k].Id
			if id.startswith( pId4 ):
				ch2pId[ds.GetDataAt(k, 4)] = id
		for b in bsList:
			chId = b.Name.split('.')[2]
			if chId in ch2pId:
				b.Id = ch2pId[chId]
			else:
				b.Id = chId

	mp = New.Map3DView(bsList)
	info = MapInfo()
	info.pId = pId
	info.pLen = bsList.Count
	info.Mtd = 'PDB'
	info.PT = SimplifyTitle(pdbTitle)
	info.Set('SmR', smtRatio)
	info.Set('HA', includeHA)
	info.Set('Eps', eps)
	mp.Description = info.ToStr()
	mp.Title = f'{pId}, Len:{bsList.Count}:  {info.PT}'
	mp.GlyphSet = '36 Clusters||||Colored Balls'
	mp.ReadOnly = True
	mp.ShowPerformance = False
	mp.ShowBoundingBox = False
	mp.GlyphSize = glyphSize
	mp.GlyphOpacity = glyphOpacity
	mp.Show()
	mp.HiddenBodySize = 6
	mp.HiddenBodyColor = New.Color('White')
	mp.NormalizeView()
	return mp

def ShowProteinList(pList, includeHA, atName, smtRatio=0, glyphSize=1.0, glyphOpacity=0.75, rp=3):
	mapStore = NewMapStore(atName, clearStore=True)
	if mapStore != None:
		mapStore.atlas.Description = f'DS:{vv.Dataset.Name}'
	for k, pId in enumerate(pList):
		vv.Title = f'Loading {pId}: {k+1}-th of {len(pList)}'
		chainNames = GetChainName(pId)
		ShowPDB(pId, chainNames=chainNames, includeHA=includeHA, rp=rp, smtRatio=smtRatio, glyphSize=glyphSize, glyphOpacity=glyphOpacity)
		if mapStore != None:	
			mapStore.AddMap('D3dRender').Close()
	if mapStore != None:
		ma = mapStore.atlas
		for item in ma.Items: 
			item.IconWidth = 250
		ma.Show()
		ma.ArrangeItems(False)
		ma.OnItemsSelected = ''

def GetChainName(pId):
	ds = vv.Dataset
	chIdx = ds.IndexOfColumn('ChainName')
	if chIdx >= 0:
		rowIdx = ds.BodyIndexForId(pId)
		chName = ds.GetDataAt(rowIdx, chIdx)
		return [ chName ]
	else:
		return None

def GetChainById(cId):	
	_, bList, _, _ = LoadCifData(cId, chainNames=GetChainName(cId))
	return bList

def UnFoldProteinList(pList, epochs=1000, eps=0.1, includeHA=False, wholeComplex=False, 
		samplingDist=0,  ppl=0.1, initExag=5.0, finalExag=1.0, atName=None, 
		stretch=0, clusterStretch=0.5, expandFactor=1.0, iconWidth=50, glyphSize=2.0, smtRatio=0):

	t0 = time.time()
	if wholeComplex:
		# Remove all duplicates.
		selected = set()
		pList2 = []
		for p in pList:
			if p[:4] not in selected:
				pList2.append(p)
				selected.add(p[:4])
		pList = pList2

	if samplingDist > 0:
		pList = ss.FlatSampling(pList, samplingDist)
		vv.Title = f'Sampled {len(pList)} chains!'
	else:
		vv.Title = 'Sampled all chains'

	if vv.ModifierKeys.ControlPressed:
		vv.SelectedItems = pList
		return
	
	mapStore = NewMapStore(atName, clearStore=True)	
	mds = NewMds(nt=None, epochs=epochs, is3D=False, refreshFreq=0, repeats=0, metric='EuclideanMetric',
		ppl=ppl, initExag=initExag, finalExag=finalExag, glyphSet=vv.Map.GlyphSet, glyphOpacity=1.0)	
	mds.GlyphSize = 0.75 if atName==None else glyphSize
	mds.AutoNormalizing = False
	mds.AutoScalingTsne = False

	try:
		for k, pId in enumerate(pList):
			chainNames = None if wholeComplex else GetChainName(pId)
			localPath, bList, bList2, pdbTitle = LoadCifData(pId, chainNames=chainNames)
			seqLen = bList.Count

			if not wholeComplex:
				bb = vv.Dataset.BodyForId(pId)
				for b in bList:
					b.Type = bb.Type
					b.Hidden = False
			bList = Interpolate(bList, rp=3, eps=eps, smtRatio=smtRatio)			
			if includeHA:
				bList.AddRange(bList2)
			nt = Augment2Table(bList, stretch=stretch, clusterStretch=clusterStretch, expandFactor=expandFactor)
			if nt.Rows < 8:
				continue	

			info = MapInfo()
			info.SF = stretch
			info.CF = expandFactor
			info.pId = pId
			info.pLen = bList.Count
			info.Mtd = 'PDB'
			info.PT = SimplifyTitle(pdbTitle)
			info.DS = f'DS:{vv.Dataset.Name}'
			info.Set('SmR', smtRatio)
			info.Set('HA', includeHA)
			info.Set('Eps', eps)
			if chainNames != None:
				info.Set('CNs', '|'.join(chainNames) )
			mds.SetTrainingData(nt)
			vv.Title = f'Unfolding {pId}/{seqLen:,}: {k+1}-th of {len(pList)}'

			# Mark the head red.
			bList = mds.BodyList
			bList[0].Type = 105
			for k in range(1, bList.Count-1):		
				if bList[k].Name.split('.')[2] != bList[k+1].Name.split('.')[2]:
					bList[k].Type = 110
					bList[k+1].Type = 105
			bList[bList.Count-1].Type = 110

			RunMds(mds, info=info, repeats=0)

			if mapStore != None:
				mapStore.AddRawMap(pId, mds.BodyList, scale=10)
			else:
				mds.ShowSnapshot().NormalizeView()
		mds.Close()
	except Exception as e:
		vv.Message(str(e))
	if mapStore != None:
		ma = mapStore.atlas
		MatchProteinMap(ma, iconWidth)
		info.Set('TM', round(time.time()-t0, 3))
		ma.Description = info.ToStr()
		ma.Show()
		ma.DataChanged = True # since the Show() clears the DataChanged flag.

# CreateProteinMaps() is a fast version of UnFoldProteinList(), it is limited to sequences with less than 23K PP.
def CreateProteinMaps(pList, atlasName, tP):
	epochs, intRp, stretch, ppl, initE, finalE = tP
	maxRows = MaxRows(vv.Dataset, pList, intRp)
	tsne = FastTsne(maxRows, 4, 2, epochs, ppl, initE, finalE)
	L = len(pList)
	mapStore = AtlasMapStore(atlasName) if L > 4 else None
	t0 = time.time()
	for k, pId in enumerate(pList):
		bList = LoadChain0(pId)
		bList = Interpolate1Chain(bList, intRp)
		nt = ss.AugmentByStretch(bList, stretch, intRp)
		nt = tsne.Fit(nt)
		if nt == None:
			continue
		bList = nt.ToBodyList()
		if mapStore == None:
			cs.FitByPCA(New.MapSnapshot(bList), 15.0).Show()
		else:
			mapStore.AddRawMap(pId, bList, scale=60)
			if (k+1)%10==0: 
				vv.Title = f'Fitted {pId}/{bList.Count}: {k+1}-th of {L}'
		vv.DoEvents()
	if mapStore != None:
		info = MapInfo()
		info.Set('TM', round(time.time()-t0, 3))
		info.Set('tP', tP)
		ma = mapStore.atlas
		ma.Show()
		MatchProteinMap(ma, 50)
		ma.Description = info.ToStr()

def SimplifyTitle(title):
	return title.replace(':', '..').replace(';', '.,')

def LoadCifData(pId, chainNames=None):
	localPath = pId if pId.endswith('.cif') else Download3DInfo(pId[:4])
	bsList = cs.LoadCif(localPath, chainNames)
	return localPath, bsList, cs.GetHeteroChains(), cs.GetTitle()

def OpenCifFile(pId):
	vv.StartProcess("vi", PdbCacheFile(pId))

def Augment2Table(bList, stretch, clusterStretch=1.0, expandFactor=1.0):

	if expandFactor != 1.0:
		bList = New.BodyListClone(bList)
		bList = cs.LocalExpand(bList, expandFactor)
	nt = New.NumberTable(bList,3)

	if stretch == 0 and clusterStretch == 0:
		return nt
	if nt.Rows <= 1:
		return nt	

	if clusterStretch == 0:
		nt.AddColumns(1)
	else:
		nt.AddColumns(4)

	M = nt.Matrix
	rsList = nt.RowSpecList
	# get the number of interpolation points, ipp, which is normally 8
	dx = 0
	for ipp in range(1, min(64, rsList.Count)):		
		if rsList[ipp].Id[0] == 'A':
			dx = 0.1*stretch/ipp
			break
	if dx == 0:
		return nt

	meanV = {}
	meanCnt = {}
	for row, rs in enumerate(rsList):
		if rs.Type not in meanCnt:
			meanCnt[rs.Type] = 0
			meanV[rs.Type] = [0, 0, 0]
		meanCnt[rs.Type] += 1
		V, R = meanV[rs.Type], M[row]
		for dim in range(3):
			V[dim] += R[dim]

	for row, rs in enumerate(rsList):
		if (row==0) or (rs.Type != rsList[row-1].Type): 
			offset = -0.5*meanCnt[rs.Type]*dx
		# hetero atoms don't participate in the unfold stretching
		if rs.Id[0] == 'H': continue
		#if rs.Name[0] == 'r': continue
		M[row][3] += offset
		offset += dx

	if clusterStretch != 0:
		for t in meanCnt:
			n, V = meanCnt[t], meanV[t]
			for dim in range(3):
				V[dim] = clusterStretch * V[dim]/n
		for row, rs in enumerate(rsList):
			V, R = meanV[rs.Type], M[row]
			for dim in range(3):
				R[4+dim] = V[dim]
	return nt

def Download3DInfo(pId):
	from os.path import exists
	#from urllib.request import urlretrieve
	import requests
	localPath = PdbCacheFile(pId)	
	if not exists(localPath):
		CheckCacheDir()
		remotePath = f'https://files.rcsb.org/download/{pId[:4]}.cif'
		#urlretrieve(remotePath, localPath)
		print(f'Downloading {pId}...')
		request = requests.get(remotePath, timeout=30, stream=True)
		with open(localPath, 'wb') as f:
			for chunk in request.iter_content(1024 * 1024):
				f.write(chunk)
	return localPath


def HideInterpolates():
	for b in pp.BodyList:
		if b.Id.startswith('i'):
			b.Hidden = True
	pp.TheForm.HiddenBodySize = 4
	pp.RedrawAll()

def ShowHelix():
	vv.SelectedItems = [b.Id for b in pp.BodyList if b.Name.endswith('.h')]

def ShowBetaSheet():
	vv.SelectedItems = [b.Id for b in pp.BodyList if b.Name.endswith('.b')]


def LoadChain0(pId):
	from os.path import exists
	cacheFile = ChainCacheFile(pId)
	if not exists(cacheFile):
		UnpackChains([pId[:4]])
	return csLoad.LoadChain(cacheFile)

def LoadChain(pId):
	bList = LoadChain0(pId)
	return New.NumberTable(bList, 3)

def LoadSeq(pId):
	from os.path import exists
	cacheFile = ChainCacheFile(pId)
	if exists(cacheFile):
		return csLoad.LoadSeq(cacheFile)
	else:
		seq = []
		nt = LoadChain(pId)
		for rs in nt.RowSpecList:
			seq.append(rs.Name[0])
		return ''.join(seq)

def Interpolate(bList, rp=3, eps=0.1, smtRatio=0):
	bs = New.BodyList()
	k0 = 0
	t0 = bList[0].Type
	chIdx  = 0
	for k in range(bList.Count+1):
		if (k == bList.Count) or (bList[k].Type != t0):
			D = bList.GetRange(k0, k-k0)
			if smtRatio != 0:
				cs.LocalSmoothen(D, smtRatio, 8)
			D = cs.Interpolate3D(D, rp, eps, bs.Count, chIdx)
			chIdx+=1
			bs.AddRange(D)
			if k < bList.Count:
				k0 = k
				t0 = bList[k0].Type
	return bs

def Interpolate1Chain(bList, rp=3, eps=0.1, smtRatio=0):
	marked = bList[0].Type == 105
	if marked:
		bList[0].Type = bList[1].Type
		bList[bList.Count-1].Type = bList[1].Type			
	if smtRatio != 0:
		cs.LocalSmoothen(bList, smtRatio, 8)
	bList = cs.Interpolate3D(bList, rp, eps, bList.Count, 0)
	if marked:
		bList[0].Type = 105
		bList[bList.Count-1].Type = 110
	return bList

def UnFoldMap(pMap, epochs=1000, ppl=0.1, staged=False, repeats=1, stretch=0, clusterStretch=1.0, expandFactor=1.0, initExag=10.0, finalExag=1.0, is3D=False):
	bList = pMap.BodyListEnabled()
	nt = Augment2Table(bList, stretch=stretch, clusterStretch=clusterStretch, expandFactor=expandFactor)
	mds = NewMds(nt, is3D=is3D, glyphSet=pMap.GlyphSet, initExag=initExag, finalExag=finalExag,
		epochs=epochs, ppl=ppl, staged=staged)
	info = MapInfo(pMap.Description).SetMds(mds)
	info.SF = stretch
	info.CF = expandFactor  # Local expanding factor
	winTitle = pMap.Title
	mds.GlyphSize = 0.5
	RunMds(mds, repeats=repeats, info=info)
	vv.LastView.Title = winTitle
	if repeats != 0:
		mds.Close()

# pId=pList[0]
# Extract chains from PDB complex and store then in current table. Duplicates will be removed.
def LoadChains(pId, aaChains=True, rnaChains=False, dnaChains=False):
	ds = vv.Dataset
	if (ds.Columns != 5) or (ds.ColumnSpecList[4].Id != 'ChainName'):
		vv.Message('Current dataset has invalid format: pid;repeats;seq;len;chainName')
		return None, None, None
	_, bList, _, pdbTitle = LoadCifData(pId)
	if bList == None:
		print('Failed to load cif file: ', pId)
		return None, None, None
	chList = []
	chType = -1    # current chain type
	chName = ''	  # current chain name.
	seqList = []
	ppType = -1   # polypeptide type: 0: aa-pp, 99: rna-pp, 97: dna-pp
	for b in bList:
		if b.Type == chType:
			pp = b.Name[0] if ppType == 0 else b.Name[2]
			seqList.append(pp)
		else:
			if len(seqList) > 0:
				if (aaChains and ppType==0) or (rnaChains and ppType==1) or (dnaChains and ppType==2):
					pSeq = ''.join(seqList)
					chList.append( (chName, ppType, pSeq, len(pSeq)) )
			chType = b.Type
			fs = b.Name.split('.')
			chName = fs[2]
			if fs[0] == 'r':	
				ppType = 99
			elif fs[0] == 'd':
				ppType = 97
			else:
				ppType = 0
			pp = b.Name[0] if ppType == 0 else b.Name[2]
			seqList = [ pp ]
	if len(seqList) > 0:
		if (aaChains and ppType==0) or (rnaChains and ppType==99) or (dnaChains and ppType==97):
			pSeq = ''.join(seqList)
			chList.append( (chName, ppType, pSeq, len(pSeq)) )
	# merge the repeated sequences:
	chSet = {}
	chInfo = {}
	totalLength = 0
	for (chId, ppType, pSeq, seqLen) in chList:
		totalLength += seqLen
		if pSeq in chSet:
			chSet[pSeq] += 1
		else:
			chSet[pSeq] = 1
			chInfo[pSeq] = (chId, ppType)
	for k, ch in enumerate(chSet):
		repeats = chSet[ch]
		chLen = len(ch)
		chId, ppType = chInfo[ch]
		seq = ch if ppType == 0 else ch.lower()
		b = ds.AddRow(f'{pId}_{k}', None,  ppType, [pId, str(repeats), seq, str(chLen), chId])
		if b == None:
			raise Exception('Failed: '+vv.LastError)
	return len(chList), totalLength, pdbTitle

# Unpack all chains in a PDB directory and store them in current dataset.
# A summary table about each protein will displayed.
def LoadAllChains(pList=None, aaChains=True, rnaChains=False, dnaChains=False):
	import os
	ds = vv.Dataset
	if (ds.Columns != 5) or (ds.ColumnSpecList[4].Id != 'ChainName'):
		vv.Message('Current dataset has invalid format: pid;repeats;seq;len;chainName')
		return
	if pList == None:
		pList = [f[:4] for f in os.listdir(PDB_CACHE) if f.endswith('.cif')]	
	chCount = 0
	pTable = New.FreeTable()
	pTable.AddColumn('Chains', True)
	pTable.AddColumn('Size', True)
	pTable.AddColumn('Title', False)

	print(f'Importing {len(pList)} proteins')
	for k, pId in enumerate(pList):
		if (k+1)%50 == 0:
			print(k+1, ': ', pId, chCount)
		chCnt, totalLen, title = LoadChains(pId, aaChains=aaChains, rnaChains=rnaChains, dnaChains=dnaChains)
		if chCnt == None:
			continue
		chCount += chCnt
		pTable.AddRow(pId, 0, [str(chCnt), str(totalLen), title])
		vv.DoEvents()
	ds.CommitChanges()
	return pTable

def SaveChain(chId, chain):
	cacheFile = ChainCacheFile(chId)
	with open(cacheFile, 'w') as outFile:
		for b in chain:
			outFile.write(f'{b.Id}|{b.Name}|{b.Type}|{b.X:.2f}|{b.Y:.2f}|{b.Z:.2f}\n')

def UnpackChains(pList=None):
	import os
	CheckCacheDir()
	if pList == None:   # Unpack all cif files.
		pList = [f[:4] for f in os.listdir(PDB_CACHE) if f.endswith('.cif')]	
	chainsCount = 0
	nm2id = {}
	ds = vv.Dataset
	for b in ds.BodyList:
		nm = ds.StringAt(b.Id, 4)
		nm2id[b.Id[:4]+'_'+nm] = b.Id
	print(f'Unpacking {len(pList)} cif files...')
	for k, pId in enumerate(pList):	
		_, bList, _, pdbTitle = LoadCifData(pId)
		if bList == None:
			print('Failed to load:', pId)
			continue
		preChName = None
		chain = []
		if k % 50 == 0:
			vv.Title =  f'Unpackinging {k}: {pId} {chainsCount}'
		vv.DoEvents()
		for b in bList:
			chNm = b.Name.split('.')[2]
			if chNm == preChName:
				chain.append(b)
			else:
				if preChName != None:
					id_nm = pId + '_' + preChName
					if id_nm in nm2id:
						chainsCount += 1
						SaveChain(nm2id[id_nm], chain)
				# start a new chain with chName and b as first point
				preChName = chNm
				chain = [ b ]
		# The last chain
		if len(chain) > 0:
			id_nm = pId + '_' + preChName
			if id_nm in nm2id:
				SaveChain(nm2id[id_nm], chain)

''' Unpack all cif files. Call this after cleaned ChainCache dir.
UnpackChains()
UnpackChains(['8FL2']) # download and unpack a single cif.
'''

def PreloadPDB(sList):
	from os.path import exists
	pList = sList.split(',')
	print(f'Preloading {len(pList)} pIds...')
	pList = list(set([p[:4] for p in pList]))
	print(f'Preloading {len(pList)} files...')
	cnt = 0
	for k, pId in enumerate(pList):
		if k%50 == 0: 
			print(k)
		if not exists(PdbCacheFile(pId)):
			try:
				Download3DInfo(pId)
				vv.DoEvents()
			except Exception as e:
				print(f'EXCEPTION ({k}): ', pId, str(e))
				raise e
			cnt+=1
	print(f'Downloaded {cnt} PDB files')
	return pList

def InitDatabase(dsName, description):
	dsName = vv.Folder.NewDataset(dsName, description).Name
	vv.Folder.OpenDataset(dsName)
	vv.Map.GlyphSet = 'Ordered 64|36 Clusters|Red Green'
	ds = vv.Dataset
	ds.AddColumn('PID', 0, '', 0)
	ds.AddColumn('Repeats', 1, '0', 1)
	ds.AddColumn('ProteinSeq', 0, '', 2)
	ds.AddColumn('SeqLen', 1, '0', 3)
	ds.AddColumn('ChainName', 0, '', 4)
	ds.CommitChanges()

def MergeTableToDataset(tb, dsName):
	oldDsName = vv.Dataset.Name
	ds = vv.Folder.OpenDataset(dsName)
	if ds == None:
		vv.Folder.NewDataset(dsName, '')
		ds = vv.Folder.OpenDataset(dsName)
		ds.AddColumn('Chains', 1, '0', 0)
		ds.AddColumn('Size', 1, '0', 1)
		ds.AddColumn('Title', 0, '', 2)
		ds.CommitChanges()
	for row in range(tb.Rows):
		rowId = tb.RowSpecList[row].Id		
		if ds.IndexOfRow(rowId) < 0:
			ds.AddRow(rowId, '', 0, tb.Matrix[row])	
	ds.CommitChanges()
	vv.Folder.OpenDataset(oldDsName)

# import a protein list into a new dataset table.
def ImportPDBList(sList, dsName, dsDescription=''):
	pList = PreloadPDB(sList)
	InitDatabase(dsName, dsDescription)
	infoTable = LoadAllChains(pList, True, True, True)
	MergeTableToDataset(infoTable, "P-Info")

'''

import os
sList = [f[:4] for f in os.listdir(PDB_CACHE) if f.endswith('.cif')]
print(len(sList))
sList = ','.join(sList)
ImportPDBList(sList, 'AllPdb')

Steps to import a list of PDB id into VisuMap:

sList = vv.GuiManager.GetClipboard()
pList = sList.split(',')

sList = '4WSX,4QY1,4N5Z,2FK0,4N5Y,4JUL,6ID2,4MHI,1RU7,4WST,3M6S'
sList = ','.join(vv.AllItems)
print(len(sList.split(',')))
ImportPDBList(sList, 'Archaea')

infoTable = LoadAllChains(['9A1Z'], True, True, True)


'''
