# DeepScaling.pyn
#
# Do multidimensional scaling with a neural network. Reduce given table Y to 
# inDim-dimensional table X, a la NN backprobagation: X<-Y
#
#------------------------------------------------------------------------------
import random
vv.Import('CommonUtil.pyn')
vv.Import('VsModelling.pyn')
InitVmd()
vmd.Clear()

#------------------------------------------------------------------------------

def Logger(epoch, cost):
	global inDim
	tm = (time.time() - vmd.startTime)/(epoch+1)
	logTitle = f'Epoch: {epoch+1}, Cost: {cost:_.2f}, E/s: {tm:.3f}'
	if inDim==1:
		#UpdateInMap5(epoch, cost, logTitle)
		#UpdateInMap(epoch, cost, logTitle)
		UpdateOutMap(epoch, cost, logTitle)
	else:
		UpdateOutMap(epoch, cost, logTitle)
		#UpdateInMap_2D(epoch, cost, logTitle)

def UpdateInMap(epoch, cost, title):
	global spMap
	npSeq = X.numpy().flatten()
	if (spMap == None) or spMap.TheForm.IsDisposed:
		spMap = ShowSpectrum(npSeq)
	else:
		items = spMap.ItemList
		for i in range(items.Count):
			items[i].Value = npSeq[i]
		spMap.ResetScaling()
	spMap.Title = title
	return spMap

def UpdateInMap_2D(epoch, cost, title):
	pX = X.numpy()
	if inDim<=3:
		Update2DMap(4000*pX+[400], title=title)
	else:
		UpdateXyMap(pX, title=title)

def UpdateInMap2(epoch, cost, title):
	global spMap
	npSeq = X.numpy().flatten()
	if (spMap == None) or spMap.TheForm.IsDisposed:
		spMap = New.MapSnapshot(True).Show()
	minV, maxV = np.min(npSeq), np.max(npSeq)
	rangeV = maxV - minV
	N = npSeq.shape[0]
	pos = np.empty([N, 3], dtype=np.float32)
	posY = 200 if (int(epoch/vmd.reportFreq)%2 == 0) else 400
	sz = spMap.MapLayout.Width
	for i in range(N):
		pos[i] = sz*(npSeq[i] - minV)/rangeV, posY, 0
	spMap.MoveBodiesTo(mm.ToMatrix32(pos), 150, 20)  
	spMap.Title = title
	return spMap

def UpdateInMap3(epoch, cost, title):
	global spMap
	npSeq = X.numpy().flatten()
	if (spMap == None) or spMap.TheForm.IsDisposed:
		spMap = ShowBarView(npSeq)
	else:
		spMap.MoveTo(mm.ToArray64(npSeq), 20, 30)
	return spMap

preX = None
def UpdateInMap4(epoch, cost, title):
	global spMap
	global preX
	if (spMap == None) or spMap.TheForm.IsDisposed:
		spMap = New.HistoryView().Show()
	newX = X.numpy()
	if preX is not None:
		varX = float( np.sum(np.abs(newX-preX)) )
		spMap.AddStep(varX)
	preX = newX
	spMap.Title = title
	return spMap

seqHist = None
colIdx = 0
def UpdateInMap5(epoch, cost, tittle):
	global seqHist, colIdx
	if seqHist is None: 
		N = dY.shape[0]
		dim = int(epochs/vmd.reportFreq)
		seqHist = np.zeros([N, dim], dtype=np.float32)
		colIdx = 0
	seqHist[:, colIdx] = X.numpy().flatten()[:]
	colIdx += 1

def UpdateOutMap(epoch, cost, title=None):
	pY =  md(X, training=False).numpy()
	outDim = dY.shape[1]
	outMap = Update2DMap(pY) if outDim <= 3 else	UpdateXyMap(pY)
	if title != None:
		outMap.Title = title
	return outMap

def UpdateXyMap(npTable, title=None):
	global xyMap
	if (xyMap == None) or xyMap.TheForm.IsDisposed:
		xyMap = ShowXyMap(npTable)
	else:
		mm.CopyToTable(npTable, xyMap.GetNumberTable())
		xyMap.Redraw()
	if title is not None: xyMap.Title = title	
	return xyMap

def Update2DMap(npTable, title=None):
	vmd.OpenLogMap()
	vmd.logMap.MoveBodiesTo(mm.ToMatrix32(npTable))
	if title is not None: vmd.logMap.Title = title	
	return vmd.logMap

#-------------------------------------------------------------------------------------

@tf.function(jit_compile=True)
def TrainBatch(md, bIdx):
	with tf.GradientTape() as tape:
		bX, bY = tf.gather(X, bIdx), tf.gather(Y, bIdx)
		pY = md(bX, training=True)
		loss = md.lossFct(bY, pY) 
		#loss = md.lossFct(tf.nn.softmax(bY), tf.nn.softmax(pY))
	grads = tape.gradient(loss, md.trainable_variables)
	md.optimizer.apply_gradients(zip(grads, md.trainable_variables))
	return loss

def TrainScalingModel(md, epochs, dsBatchs, LR):
	md.optimizer = AdamOptimizer(epochs*len(dsBatchs), LR, discreteDecay=True)
	vmd.EnableLog()	
	TrainBatch.__init__(TrainBatch.python_function, 'TrainBatch', jit_compile=True)
	vmd.stopTraining = False
	vmd.startTime = time.time()
	for epoch in range(epochs):  
		cost = 0
		for i, bIdx in enumerate(dsBatchs):
			cost += TrainBatch(md, bIdx)
			if i%50==0: vv.DoEvents()
		random.shuffle(dsBatchs)
		if vmd.stopTraining:	break
		ReportTraining(epoch, cost, Logger)
	vmd.trainingTime = time.time() - vmd.startTime

def ToBatchList(dY, inDim, spread, batchSize):
	N = dY.shape[0]
	Y = tf.convert_to_tensor(dY)
	dX = RandomMatrix(spread, N, inDim)
	X = tf.Variable(dX, trainable=True)
	outDim = dY.shape[1]
	
	if outDim == 3: 
		keyItem = 'k3d'
	elif outDim == 2:
		keyItem = 'k2d'
	else:
		keyItem = None

	if keyItem is not None:	
		keyList = vv.AtlasManager.ReadValueList('Instance1', keyItem)
		if keyList is None or keyList.Count != N:
			vv.Message('Invalid sorting keys')
			vv.Return()
		sortKey = [it.Value for it in keyList]
		#sortKey = [b.Type for b in vv.Dataset.BodyListEnabled()]
		indexList = np.argsort(sortKey)
	else:
		indexList = np.array(range(N))

	#np.random.shuffle(indexList)
	batchList = []
	for n in range(0, N, batchSize):
		batchList.append( tf.convert_to_tensor(indexList[n:n+batchSize]) )
	return X, Y, dX, batchList

def ClearSession():
	global md, X, Y, dsBatchs
	if md is None:
		return
	del X
	del Y
	for bt in dsBatchs:
		del bt
	del md
	md = None
	keras.backend.clear_session()

def NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR):
	global md
	md = DeepScalingModel(X, Y, dimList, DR)
	TrainScalingModel(md, epochs, dsBatchs, LR)
	return md

#------------------------------------------------------------------------------
# Create model and train it.
#

def Main():
	global md, X, Y, inDim, DR, LR, dsBatchs, mdPre

	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	pY = md(X, training=False).numpy()
	meanL1 = np.sum(np.abs(pY-dY))/dY.shape[0]
	sTitle = f'Epochs/DR/LR: {epochs}/{DR:.3f}/{LR:.5f}, Mean-L1: {meanL1:.3f}'
	ShowInMap(sTitle)
	#ShowMap(pY, title = 'Output: ' + sTitle)
	if seqHist is not None:
		ShowHeatmap(seqHist, 'SeqHist', bodyList)

def Main2x():
	global md, X, Y, inDim, DR, LR, dsBatchs

	pX = []
	vv.Echo('Training dimension 1')
	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	if vmd.stopTraining:	
		return
	pX.append(X.numpy())
	pY = md(X, training=False).numpy()

	inDim = 1
	X, Y, dX, dsBatchs = ToBatchList(dY, inDim, spread, batchSize)
	Y =  Y - pY
	X.assign(dX)
	vv.Echo('Training dimension 2')
	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	if vmd.stopTraining:	return
	pX.append(X.numpy())
	pY += md(X, training=False).numpy()
	
	pX = np.concatenate(pX, axis=1)
	meanErr = np.sum(np.abs(pY-dY))/dY.shape[0]
	sTitle = f'Epochs/DR/LR: {epochs}/{DR:.3f}/{LR:.5f}, Mean-L1: {meanErr:.3f}'
	pX = 5000*pX+[400]
	ShowMap(pX, title = 'Input: ' + sTitle)
	ShowMap(pY, title = 'Output: ' + sTitle)

def Main3x():
	global md, X, Y, inDim, DR, LR, dsBatchs

	pX = []
	vv.Echo('Training dimension 1')
	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	if vmd.stopTraining:	return
	pX.append(X.numpy())
	pY = md(X, training=False).numpy()

	Y =  Y - pY
	X.assign(dX)
	vv.Echo('Training dimension 2')
	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	if vmd.stopTraining:	return
	pX.append(X.numpy())
	outY = md(X, training=False).numpy()
	pY += outY

	Y =  Y - outY
	X.assign(dX)
	vv.Echo('Training dimension 3')
	md = NewModel(X, Y, dimList, DR, epochs, dsBatchs, LR)
	if vmd.stopTraining:	return
	pX.append(X.numpy())
	outY = md(X, training=False).numpy()
	pY += outY
	
	pX = np.concatenate(pX, axis=1)

	meanErr = np.sum(np.abs(pY-dY))/dY.shape[0]
	sTitle = f'Epochs/DR/LR: {epochs}/{DR:.3f}/{LR:.5f}, Mean-L1: {meanErr:.3f}'
	pX = 5000*pX+[400]
	ShowMap(pX, title = 'Input: ' + sTitle)
	ShowMap(pY, title = 'Output: ' + sTitle)


#------------------------------------------------------------------------------
mdPre = None
def ManifoldLayer(P, topo):
	global mdPre
	if topo == 0:
		mdPre = None
		return P

	input = P
	
	okDim = 3 if topo==5 else 2
	Check(inDim==okDim, 'Invalid input dimension')

	if topo == 1:
		# A strip 
		a, b = 1.0, 0.25
		P *= [a, b]
		visP = P	
	elif topo==2:
		# circle x line
		Q, b, c = 50*P[:,:1], 10, 0.01
		P = tf.concat([b*tf.math.sin(Q), b*tf.math.cos(Q), c*P[:, 1:2]], 1)
		visP = P
	elif topo==3:
		# 2D-sphere
		a, b = 50, 10
		P *= a
		P0, P1 = P[:,0:1], P[:,1:2]
		P = b*tf.concat([tf.math.cos(P0)*tf.math.sin(P1), 
			tf.math.sin(P0)*tf.math.sin(P1), tf.math.cos(P1)], 1)
		visP = P
	elif topo==4:
		# torus: circle1 x circle2
		a, b = [50, 20], [10.0, 0.01, 10.0, 0.01]
		P = b*tf.concat([tf.math.sin(a*P), tf.math.cos(a*P)], 1)	
		alpha = tf.math.atan2(P[:,0], P[:,2])
		beta = tf.math.atan2(P[:,1], P[:,3])
		alpha = 400.0*(alpha/math.pi + 1.0)
		beta = 400.0*(beta/math.pi + 1.0)
		alpha = tf.reshape(alpha, [-1, 1])
		beta = tf.reshape(beta, [-1, 1])
		visP = tf.concat( [alpha, beta], axis=1)
	elif topo==5:
		# real projective 3D space.
		a, b = 30, 15
		P *= a
		P0, P1, P2 = P[:,0:1], P[:,1:2], P[:,2:3]
		x0 = tf.math.cos(P0)
		x1 = tf.math.sin(P0) * tf.math.cos(P1)
		x2 = tf.math.sin(P0) * tf.math.sin(P1) * tf.math.cos(P2)
		x3 = tf.math.sin(P0) * tf.math.sin(P1) * tf.math.sin(P2)
		visP = tf.concat([x0, x1, x2, x3], 1)
		P = b*visP
	elif topo==6:
		# real projective 2D plance:
		a, b = 40, 10
		P0, P1 = a*P[:,0:1], a*P[:,1:2]
		x = tf.math.cos(P0)*tf.math.sin(P1) 
		y = tf.math.sin(P0)*tf.math.sin(P1)
		z = tf.math.cos(P1)
		visP = tf.concat([x, y, z], 1)
		P = b*tf.concat([x*y, x*z, y*y - z*z, 2*y*z], 1)

	mdPre = keras.Model(input, visP)
	mdPre.topo = topo
	return P

# fit a numpy array to a map
def Fit2Map(pX, size=700):
	pX -= np.min(pX, axis=0)
	pX *= size / np.average(np.max(pX,axis=0))
	return pX

# convert a numpy array to body-list.
def ToBodyList(pX):
	bList = New.BodyListClone(vv.Dataset.BodyListEnabled())
	for i, b in enumerate(bList):
		b.X, b.Y, b.Z = pX[i]
	return bList

def ShowInMap(title):
	title = 'Input: ' + title
	if mdPre is None:
		pX = Fit2Map(X.numpy())
		pX -= np.min(pX, axis=0)
		pX *= 700 / np.average(np.max(pX,axis=0))
		ShowMap(pX, title = title)
		return

	title = title + f'; topo:{mdPre.topo}'

	pX = mdPre(X).numpy()
	if mdPre.topo == 1:  # rectangle
		pX = Fit2Map(pX)
		xMap = ShowMap(pX, title = title)
	elif mdPre.topo == 2: # cirle x line: 
		pX = Fit2Map(pX, size=400)
		pX[:,2] *= 1000
		xMap = New.Map3DView(ToBodyList(pX))
		xMap.Title = title
		xMap.Show()
		xMap.NormalizeView()
	elif mdPre.topo == 3:  # sphere
		pX = Fit2Map(pX, size=400)
		sMap = New.SphereView(ToBodyList(pX))
		sMap.Title = title
		sMap.Show()
	elif mdPre.topo == 4:  # torus
		xMap = ShowMap(pX, title = title)	
		xMap.MapLayout.MapTypeIndex = 100
		xMap.MapLayout.Width = 800
		xMap.MapLayout.Height = 800
		xMap.RedrawAll()
	elif mdPre.topo == 5: # 3D sphere
		sp3d = New.Sphere3D(bodyList, mm.ToMatrix64(pX), False)
		sp3d.Show().Title = title
		ShowMap3D(200*X.numpy(), title)
	elif mdPre.topo == 6: # 2D real projective plane
		pX = Fit2Map(pX, size=400)
		sMap = New.ProjectiveSphereView(ToBodyList(pX))
		sMap.Title = title
		sMap.Show()
		ShowMap(1000*X.numpy(), None, title)

def DeepScalingModel(X, Y, dimList, DR):
	global drTopology
	P = input = keras.Input(shape=(X.shape[1]), dtype=tf.float32)
	P = ManifoldLayer(P, topo=drTopology)

	for k, dim in enumerate(dimList):
		P = DenseLayer(dim, 'leaky_relu') (P)
		if (k <= 4) and (DR>0): 
			P = keras.layers.Dropout(DR)(P)
		#Jumping connections for better performance
		if k==0: P1 = P  
		if k==4: P += P1

	P = DenseLayer(Y.shape[1], 'sigmoid') (P)
	output = OutScaling(Y, gape=0.0) (P)

	md = keras.Model(input, output, name=f'Scaling')
	md.lossFct = keras.losses.MeanSquaredError()
	#md.lossFct = keras.losses.KLDivergence()
	md.X = X   # this statment will add X to md.trainable_variables!
	return md

#------------------------------------------------------------------------------
# Load data and settings

md, xyMap, spMap = None, None, None
vmd.reportFreq = 20
bodyList = vv.Dataset.BodyListEnabled()
#dY = GetMapData()
dY = GetDatasetData()

inDim, dimList = 2, 6*[256]
spread, batchSize, DR, LR, epochs = 0, 25, 0.25, 0.000_25, 1000
drTopology =  0

X, Y, dX, dsBatchs = ToBatchList(dY, inDim, spread, batchSize)
Main()

'''
for repeats in range(7):
	drTopology = repeats
	inDim = 3 if drTopology==5 else 2
	ClearSession()
	X, Y, dX, dsBatchs = ToBatchList(dY, inDim, spread, batchSize)
	Main()
	if vmd.stopTraining:	break
'''