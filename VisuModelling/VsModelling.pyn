import sys, math, time
import numpy as np
import tensorflow as tf
from tensorflow import keras
vv.Import('CommonUtil.pyn')

class ModellingConfiguration:
	def __init__(self):
		self.model = None
		self.ds = None
		self.log = None
		self.reportFreq = 50
		self.trainingTime = 0
	def EnableLog(self):
		if (self.log == None) or self.log.TheForm.IsDisposed:
			self.log = New.HistoryView().Show()
			self.log.OnClose('@vmd.stopTraining=True')
	def Clear(self):
		if self.model is not None:
			del self.model
			self.model = None
		if self.ds is not None:
			if self.ds.tensors is not None:
				del self.ds.tensors
				self.ds.tensors = None
			del self.ds
			self.ds = None

class OutScaling(keras.layers.Layer):
	def __init__(self, D):
		super(OutScaling, self).__init__()
		colMax = np.max(D, axis=0)
		colMin = np.min(D, axis=0) 
		colCenter = 0.5*(colMax + colMin)
		colFact = 1.025*(colMax - colMin)
		self.colScale = colFact
		self.colShift =  colCenter - 0.5*colFact
	def call(self, inputs):
		return self.colScale * inputs + self.colShift

#-------------------------------------------------------------------------
def CheckGPU():
	vv.Echo( "GPU Available: " + str( tf.test.is_gpu_available() ))
	vv.Echo('Num GPUs Available: %d'%(len(tf.config.list_physical_devices('GPU'))))
	vv.Echo('Device Name: ' + tf.test.gpu_device_name())

def ShuffleDataset(X, Y):
	idxList = np.arange(X.shape[0])
	np.random.shuffle(idxList)
	X = np.take(X, idxList, axis=0)
	Y = np.take(Y, idxList, axis=0)

def TrainDataset(X, Y, batchSize=25):
		if X.shape[0] != Y.shape[0]:
			vv.Message("Input and Output data have different size: %d != %d"%(X.shape[0], Y.shape[0]))
			vv.Return()
		ds = tf.data.Dataset.from_tensor_slices((X, Y))
		ds = ds.shuffle(buffer_size=1024).batch(batch_size=batchSize)
		ds.tensors = []
		for bX, bY in ds:
			ds.tensors.append( (tf.convert_to_tensor(bX), tf.convert_to_tensor(bY)) )
		ds.X = X
		ds.Y = Y
		return ds

def ShowModel(md):
	md.summary(print_fn = lambda x: vv.Echo(x))

#---------------------------------------------------------------------------

def NewMapModel(layerDims, Y, dropoutRatio=0.25):
	md = keras.Sequential()
	md.add( keras.Input(shape=(layerDims[0])) )
	layers = len(layerDims)
	#md.add(keras.layers.Dropout(dropoutRatio))
	for k in range(1, layers):
		actFct = 'sigmoid' if k == (layers-1) else 'leaky_relu'
		md.add( keras.layers.Dense(layerDims[k], activation=actFct, 
			kernel_initializer='glorot_uniform', bias_initializer='zeros', use_bias=True) )
		if k == 1: md.add(keras.layers.Dropout(dropoutRatio))			
	md.add(OutScaling(Y))
	return md

def ShowPred(P, refY):
	map = ShowMap(P)
	if refY is not None:
		err = np.mean(np.linalg.norm(refY-P, axis=1))
		map.Title = 'Predicated Map:  L2 Error: %.2f, Time: %.1fs'%(err, vmd.trainingTime)
	else:
		map.Title = 'Predicated Map'

@tf.function(jit_compile=True)
def train_step(md, optimizer, lossFct, bX, bY):
	with tf.GradientTape() as tape:
		loss = lossFct(md(bX, training=True), bY)
	grads = tape.gradient(loss, md.trainable_variables)
	optimizer.apply_gradients(zip(grads, md.trainable_variables))
	return loss

def TrainModel(vmd, epochs=200, initial_lr=0.00025, logCallback=None):
	lossFct = keras.losses.MeanSquaredError()
	epochBatches = len(list(vmd.ds))
	totalBatches = epochs * epochBatches
	lr_schedule = keras.optimizers.schedules.ExponentialDecay(
		initial_learning_rate=initial_lr,
		decay_steps=int(totalBatches/20), 
		staircase=True, decay_rate=0.8)
	optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)


	#The following line makes train_step() callable for different dataset.
	train_step.__init__(train_step.python_function, 'train_step', jit_compile=True)

	vmd.stopTraining = False
	startTime = time.time()
	for epoch in range(epochs):
		cost = 0
		for bX, bY in vmd.ds.tensors:
			cost += train_step(vmd.model, optimizer, lossFct, bX, bY)
		vv.DoEvents()
		cost /= epochBatches
		if vmd.stopTraining:
			break
		if ((epoch + 1) % vmd.reportFreq == 0):
			ReportTraining(epoch, cost)
			if logCallback != None:
				logCallback(epoch, cost)
	vmd.trainingTime = time.time() - startTime

