import sys, math, time
import numpy as np
import tensorflow as tf
from tensorflow import keras
import random

class ModellingConfiguration:
	def __init__(self):
		self.model = None
		self.ds = None
		self.log = None
		self.logMap = None
		self.reportFreq = 10
		self.trainingTime = 0
		self.startTime = 0		
		self.REGRESSION = 100
		self.CLUSTERING = 101
		self.FULL_MODEL = 102

	def EnableLog(self):
		if (self.log == None) or self.log.TheForm.IsDisposed:
			self.log = New.HistoryView().Show()
			self.log.OnClose('@vmd.stopTraining=True')
			self.log.AddContextMenu('Stop Training', '@vmd.stopTraining=True')

	def Clear(self):
		vv.Map.SelectedBodies=None
		if self.model is not None:
			del self.model.lossFct
			del self.model
			self.model = None
		if self.ds is not None:
			if self.ds.tensors is not None:
				del self.ds.tensors
				self.ds.tensors = None
			del self.ds
			self.ds = None

	def OpenLogMap(self):
		if (self.logMap == None) or self.logMap.TheForm.IsDisposed:
			self.logMap = New.MapSnapshot(True)
			for b in self.logMap.BodyList:
				b.Z = 0
			self.logMap.Show()
			

class OutScaling(keras.layers.Layer):
	def __init__(self, Y, gape=0.0125):
		super(OutScaling, self).__init__()
		colMin, colMax = np.min(Y, axis=0), np.max(Y, axis=0) 
		self.colScale = (colMax - colMin)/(1-2*gape)
		self.colShift = 0.5*(colMax + colMin - self.colScale)
	def call(self, Y):
		return self.colScale * Y + self.colShift

class InScaling(keras.layers.Layer):
	def __init__(self, X):
		super(InScaling, self).__init__()
		self.inScale = float(4.0/(np.std(X) * X.shape[1]))
	def call(self, X):
		return self.inScale * X

class FullMapLoss(tf.keras.losses.Loss):
	def __init__(self, mapDim, cBias=0.9):
		super(FullMapLoss, self).__init__()
		self.mapDim = mapDim
		self.MSE = keras.losses.MeanSquaredError()
		self.Entropy = keras.losses.CategoricalCrossentropy()
		self.cBias = cBias
		self.rBias = 1.0 - cBias
	def __call__(self, Y, pY):
		mD = self.mapDim
		return self.rBias*self.MSE(Y[:,:mD], pY[:,:mD]) + self.cBias * self.Entropy(Y[:, mD:], pY[:, mD:])

class TrainDataset():
	def __init__(self, X, Y, batchSize=25, shuffle=True, sortKey=None):
		if X.shape[0] != Y.shape[0]:
			vv.Message(f'Input and Output data have different size: {X.shape[0]} != {Y.shape[0]}')
			vv.Return()
		if sortKey is not None:
			idxList = np.argsort(sortKey)
			sX, sY = X[idxList], Y[idxList]
		else:
			sX, sY = X, Y					
		if shuffle:
			idxList = np.arange(X.shape[0])
			np.random.shuffle(idxList)
			sX = np.take(sX, idxList, axis=0)
			sY = np.take(sY, idxList, axis=0)
		self.tensors = []
		for p in range(0, X.shape[0], batchSize):
			q = p+batchSize
			self.tensors.append(( tf.convert_to_tensor(sX[p:q]), tf.convert_to_tensor(sY[p:q]) ))
		self.X, self.Y = X, Y

	def ShuffleBatchs(self):
		random.shuffle(self.tensors)

	def __iter__(self):
		self.idxTensor = 0
		return self
	def __next__(self):
		if self.idxTensor < len(self.tensors):
			result = self.tensors[self.idxTensor]
			self.idxTensor += 1
			return result
		else:
			raise StopIteration
#-------------------------------------------------------------------------

def InitVmd():
	if 'vmd' not in globals():
		globals()['vmd'] = ModellingConfiguration()

def CheckGPU():
	vv.Echo(f'GPU Available: {tf.test.is_gpu_available()}' )
	vv.Echo(f'Num GPUs Available: {len(tf.config.list_physical_devices("GPU"))}')
	vv.Echo(f'Device Name: {tf.test.gpu_device_name()}')

def GetClusterPred(md, X):
	return tf.math.argmax( md(X, training=False), axis=1).numpy()

def ShowClusterPred(P, epoch, cost, map, refY=None):
	pBodyList = map.BodyList
	for i, b in enumerate(pBodyList):
		b.Type = P[i]
	map.RedrawBodiesType()
	mismatchs = 0	
	if refY is not None:
		refType = np.argmax(refY, axis=1)
		for i, t in enumerate(refType):
			if P[i] != t:
				mismatchs += 1
				pBodyList[i].Highlighted = True
			else:
				pBodyList[i].Highlighted = False
		map.Title = f'Epoch: {epoch+1}, Cost: {cost:.2g}, Misses: {mismatchs}'

def ShowModel(md):
	md.summary(print_fn = lambda x: vv.Echo(x))

def GetHits(mapDim, P, T):
	N = P.shape[0]
	hits = np.zeros(N, dtype=np.int8)
	idxList = tf.math.argmax(P[:, mapDim:], axis=1).numpy() + mapDim
	for k in range(N):
		if T[k, idxList[k]] == 1.0:
			hits[k] = 1
	return hits

def ShowPred(md, X, refY=None, refMapName=None):
	if refMapName is None:
		map = New.MapSnapshot(True).Show()
	else:
		map = New.MapSnapshot("", refMapName, True).Show()
	if map.BodyList.Count != X.shape[0]:
		vv.Message(f'Data size incompatible: {map.BodyList.Count} != {X.shape[0]}')
		vv.Return(1)
	map.Title = 'Predication'

	if md.modelType == vmd.REGRESSION:
		P = vmd.model(X, training=False).numpy()	
		map = ShowMap(P, map)
		if refY is not None:
			err = np.mean(np.linalg.norm(refY-P, axis=1))
			map.Title = f'Predication:  L2: {err:.2f}, Time: {vmd.trainingTime:.1f}'
	elif md.modelType == vmd.CLUSTERING:
		P = GetClusterPred(md, X)
		ShowClusterPred(P, 0, 0, map, refY)
		map.Title = map.Title + f',  Time: {vmd.trainingTime:.2f}'
	else:  # vmd.FULL_MODEL
		P = md(X, training=False).numpy()
		mD = md.mapDim
		Pm = P[:, :mD].copy()
		Pc = np.argmax(P[:, mD:], axis=1)
		ShowMap(Pm, map)
		ShowClusterPred(Pc, 0, 0, map, refY)
		if refY is not None:
			misses = P.shape[0] - np.sum( GetHits(mD, P, refY) )
			err = np.mean(np.linalg.norm(refY[:,:mD]-Pm, axis=1))
			map.Title = f'Predication: L2: {err:.2f}, MisMatchs: {misses}, Time: {vmd.trainingTime:.1f}'
	return map

def DenseLayer(dim, activation):
	return keras.layers.Dense(dim, activation=activation, use_bias=True,
			kernel_initializer='glorot_uniform', bias_initializer='zeros')

def AdamOptimizer(totalBatches, LR, discreteDecay=True):
	lr_schedule = keras.optimizers.schedules.ExponentialDecay(
		initial_learning_rate=LR,
		decay_steps=int(totalBatches/20), 
		staircase=discreteDecay, decay_rate=0.8)
	return keras.optimizers.Adam(learning_rate=lr_schedule)

#-------------------------------------------------------------------------------------

@tf.function(jit_compile=True)
def train_step(md, optimizer, lossFct, bX, bY):
	with tf.GradientTape() as tape:
		loss = lossFct(bY, md(bX, training=True))
	grads = tape.gradient(loss, md.trainable_variables)
	optimizer.apply_gradients(zip(grads, md.trainable_variables))
	return loss

def TrainModel(vmd, epochs, initial_lr=0.00025, logCallback=None, shuffleBatchs=False):
	optimizer = AdamOptimizer(epochs*len(vmd.ds.tensors), initial_lr)
	#The following line makes train_step() callable for different dataset.
	train_step.__init__(train_step.python_function, 'train_step', jit_compile=True)
	vmd.EnableLog()
	vmd.stopTraining = False
	vmd.startTime = time.time()
	batchCount = 0
	N = vmd.ds.X.shape[0]

	for epoch in range(epochs):  
		cost = 0
		for bX, bY in vmd.ds:
			cost += train_step(vmd.model, optimizer, vmd.model.lossFct, bX, bY)
			batchCount += 1
			if batchCount%100 == 0: vv.DoEvents()
		cost /= N		
		if vmd.stopTraining: break
		if shuffleBatchs:	vmd.ds.ShuffleBatchs()
		ReportTraining(epoch, cost, logCallback)
	vmd.trainingTime = time.time() - vmd.startTime
