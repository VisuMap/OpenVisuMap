import sys, math
import numpy as np
import tensorflow as tf
from tensorflow import keras
import time
vv.Import('CommonUtil.pyn')

class ModellingConfiguration:
	def __init__(self):
		self.model = None
		self.ds = None
		self.log = None
		self.reportFreq = 50
		self.trainingTime = 0

	def EnableLog(self):
		if (self.log == None) or self.log.TheForm.IsDisposed:
		    self.log = New.HistoryView().Show()
		    self.log.OnClose('@vmd.stopTraining=True')

	def Clear(self):
		if self.model is not None:
		    del self.model
		    self.model = None
		if self.ds is not None:
		    del self.ds
		    self.ds = None

class OutScaling(keras.layers.Layer):
	def __init__(self, D):
		super(OutScaling, self).__init__()
		colMax = np.max(D, axis=0)
		colMin = np.min(D, axis=0) 
		colCenter = 0.5*(colMax + colMin)
		colFact = 1.025*(colMax - colMin)
		#self.colScale = tf.Variable(colFact, trainable=False)
		#self.colShift =  tf.Variable(colCenter - 0.5*colFact, trainable=False)
		self.colScale = colFact
		self.colShift =  colCenter - 0.5*colFact
	def call(self, inputs):
		return self.colScale * inputs + self.colShift

#--------------------------------------------------------------------------------------------

def CheckGPU():
	vv.Echo( "GPU Available: " + str( tf.test.is_gpu_available() ))
	vv.Echo('Num GPUs Available: %d'%(len(tf.config.list_physical_devices('GPU'))))
	vv.Echo('Device Name: ' + tf.test.gpu_device_name())

def MapDataset(batchSize=25):
		X, Y = GetTrainData()
		ds = tf.data.Dataset.from_tensor_slices((X, Y))
		ds = ds.shuffle(buffer_size=1024).batch(batch_size=batchSize)
		ds.X = X
		ds.Y = Y
		return ds

def ShowModel(md):
	md.summary(print_fn = lambda x: vv.Echo(x))

#--------------------------------------------------------------------------------------------

def NewMapModel(layerDims, Y, dropoutRatio=0.25):
	md = keras.Sequential([keras.layers.Flatten(input_shape=(layerDims[0],))])
	layers = len(layerDims)
	for k in range(1, layers):
		actFct = 'sigmoid' if k == (layers-1) else 'leaky_relu'
		md.add( keras.layers.Dense(layerDims[k], activation=actFct, 
			kernel_initializer='uniform', bias_initializer='uniform', use_bias=True) )
		if k == 1:
			md.add(keras.layers.Dropout(dropoutRatio))			
	md.add(OutScaling(Y))
	return md

def ShowPred(P, refY):
	map = New.MapSnapshot(True)
	bsList = map.BodyList
	for i in range(bsList.Count):
		b = bsList[i]
		[b.X, b.Y] = P[i]
	if refY is not None:
		err = np.mean(np.linalg.norm(refY-P, axis=1))
		map.Title = 'Predicated Map:  L2 Error: %.2f, Time: %.1fs'%(err, vmd.trainingTime)
	else:
		map.Title = 'Predicated Map'
	map.Show()

def TrainModel(vmd, epochs=200, initial_lr=0.00025):
	md = vmd.model
	logger = vmd.log
	lossFct = keras.losses.MeanSquaredError()
	epochBatches = len(list(vmd.ds))
	totalBatches = epochs * epochBatches
	lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=initial_lr,
		decay_steps=int(totalBatches/20), staircase=True, decay_rate=0.8)
	optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)
	
	vmd.stopTraining = False
	startTime = time.time()
	for epoch in range(epochs):
		for bX, bY in vmd.ds:
			cost = 0
			with tf.GradientTape() as tape:
				loss = lossFct(bY, md(bX, training=True))
			grads = tape.gradient(loss, md.trainable_variables)
			optimizer.apply_gradients(zip(grads, md.trainable_variables))
			cost += loss
			vv.DoEvents()
		cost /= epochBatches
		if vmd.stopTraining:
			break
		if ((epoch + 1) % vmd.reportFreq == 0):
			logger.AddStep(float(cost))
			logger.Title = 'Eochs: %d, Cost: %.3f'%(epoch+1, cost)
	vmd.trainingTime = time.time() - startTime

#--------------------------------------------------------------------------------------------

if 'vmd' not in globals():
	vmd = ModellingConfiguration()


